Automatically generated by Mendeley Desktop 1.15.3
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Bettadapura2015,
author = {Bettadapura, Vinay and Thomaz, Edison and Parnami, Aman and Abowd, Gregory D. and Essa, Irfan},
booktitle = {2015 IEEE Winter Conference on Applications of Computer Vision},
doi = {10.1109/WACV.2015.83},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Bettadapura et al. - Leveraging Context to Support Automated Food Recognition in Restaurants - 2015 IEEE Winter Conference on Applicatio.pdf:pdf},
isbn = {978-1-4799-6683-7},
keywords = {Cameras,Feature extraction,Google,Image color analysis,Image recognition,Image segmentation,Training,automated food recognition,classifier training,computer vision,computer vision techniques,food journaling automation,food photos,image classification,image-based recognition,mobile camera pervasiveness,mobile computing,object recognition,performance evaluation,restaurant online menu databases,restaurants},
language = {English},
month = {jan},
pages = {580--587},
publisher = {IEEE},
title = {{Leveraging Context to Support Automated Food Recognition in Restaurants}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=7045937 http://www.cc.gatech.edu/{~}irfan/p/2015-Bettadapura-LCSAFRR.pdf},
year = {2015}
}
@inproceedings{Hoashi2010,
author = {Hoashi, Hajime and Joutou, Taichi and Yanai, Keiji},
booktitle = {2010 IEEE International Symposium on Multimedia},
doi = {10.1109/ISM.2010.51},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Hoashi, Joutou, Yanai - Image Recognition of 85 Food Categories by Feature Fusion - 2010 IEEE International Symposium on Multimedia.pdf:pdf},
isbn = {978-1-4244-8672-4},
keywords = {Gabor feature,automatic food image recognition system,bag-of-features,cellular phone camera,color histogram,feature extraction,feature fusion,food categories,food image recognition,food technology,gradient histogram,image fusion,image recognition,learning (artificial intelligence),multiple kernel learning,prototype system},
language = {English},
month = {dec},
pages = {296--301},
publisher = {IEEE},
title = {{Image Recognition of 85 Food Categories by Feature Fusion}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5693856},
year = {2010}
}
@article{Duan2005,
abstract = {Multiclass SVMs are usually implemented by combining sev- eral two-class SVMs. The one-versus-all method using winner-takes-all strategy and the one-versus-one method implemented by max-wins vot- ing are popularly used for this purpose. In this paper we give empirical evidence to show that these methods are inferior to another one-versus- one method: one that uses Platt’s posterior probabilities together with the pairwise coupling idea of Hastie and Tibshirani. The evidence is par- ticularly strong when the training dataset is sparse.},
author = {Duan, Kai-Bo and Keerthi, S. Sathiya},
doi = {10.1007/b136985},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2005/Duan, Keerthi - Which Is the Best Multiclass SVM Method An Empirical Study - Multiple Classifier Systems.pdf:pdf},
isbn = {978-3-540-26306-7},
issn = {0302-9743 (Print) 1611-3349 (Online)},
journal = {Multiple Classifier Systems},
pages = {278--285},
pmid = {124},
title = {{Which Is the Best Multiclass SVM Method? An Empirical Study}},
url = {http://dl.acm.org/citation.cfm?id=2134810.2134843},
volume = {3541},
year = {2005}
}
@inproceedings{Villalobos2012,
abstract = {Obesity in the world has spread to epidemic proportions. In 2008 the World Health Organization (WHO) reported that 1.5 billion adults were suffering from some sort of overweightness. Obesity treatment requires constant monitoring and a rigorous control and diet to measure daily calorie intake. These controls are expensive for the health care system, and the patient regularly rejects the treatment because of the excessive control over the user. Recently, studies have suggested that the usage of technology such as smartphones may enhance the treatments of obesity and overweight patients; this will generate a degree of comfort for the patient, while the dietitian can count on a better option to record the food intake for the patient. In this paper we propose a smart system that takes advantage of the technologies available for the Smartphones, to build an application to measure and monitor the daily calorie intake for obese and overweight patients. Via a special technique, the system records a photo of the food before and after eating in order to estimate the consumption calorie of the selected food and its nutrient components. Our system presents a new instrument in food intake measuring which can be more useful and effective.},
author = {Villalobos, Gregorio and Almaghrabi, Rana and Pouladzadeh, Parisa and Shirmohammadi, Shervin},
booktitle = {2012 IEEE International Symposium on Medical Measurements and Applications Proceedings},
doi = {10.1109/MeMeA.2012.6226636},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Villalobos et al. - An image procesing approach for calorie intake measurement - 2012 IEEE International Symposium on Medical Measuremen.pdf:pdf},
isbn = {978-1-4673-0882-3},
keywords = {Calorie intake measurement,Calories measurement,Food intake measurement,Image color analysis,Image processing,Image segmentation,Obesity,Shape,Shape recognition,Support vector machines,Thumb,World Health Organization,adults,biomedical measurement,calorie intake,constant monitoring,consumption calorie,dietitian,diseases,epidemic proportions,food intake,geriatrics,health care,health care system,image procesing approach,medical image processing,nutrient components,obesity treatment,patient treatment,rigorous control,smart system,smartphones},
language = {English},
month = {may},
pages = {1--5},
publisher = {IEEE},
title = {{An image procesing approach for calorie intake measurement}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6226636},
year = {2012}
}
@book{Theodoridis2009f,
abstract = {This chapter discusses feature selection and most of the well-known techniques used for it. Feature selection or feature reduction can be described as selecting the most important feature so as to reduce their number and at the same time retain as much as possible of their class discriminatory information. The first step in feature selection is to look at each of the generated features independently and test their discriminatory capability for the problem at hand. Treating features individually, that is, as scalars, has the advantage of computational simplicity. The chapter explores techniques measuring classification capabilities of feature vectors. The chapter also discusses the filter approach and the Wrapper approach for feature selection. In the filter approach, the optimality rule for feature selection is independent of the classifier, which is used in the classifier design stage. In Wrapper approach, for each feature, vector combination the classification error probability of the classifier has to be estimated and the combination resulting in the minimum error probability is selected. The chapter gives emphasis on the t-test. Depending on time constraints, the concepts of divergence, Bhattacharrya distance, and scattered matrices are presented and commented on. Emphasis is also given to Fisher's linear discriminant method (LDA) for the two-class case.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50007-4},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(10).pdf:pdf},
isbn = {9781597492720},
pages = {261--322},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500074},
year = {2009}
}
@article{Neelamegam2013,
abstract = {In foodstuff trade, grading of coarse food resources is essential because samples of stuffs are subjected to adulteration. In the precedent, foodstuffs in the appearance of granules were conceded through sieves or supplementary mechanical way for grading purposes. In this manuscript, investigation is performed on basmati rice granules; to appraise the act via image processing and Neural Network Pattern Recognition Tool which is implemented based on the features extracted from rice granules for categorization grades of granules. Digital imaging is acknowledged as a proficient system, to haul out the features from rice granules in a non-contact mode. Images are acquired for rice using camera. Image Pre-processing techniques, Adaptive thresholding, Canny edge detection, Feature extraction are the checks that are performed on the acquired image using image processing method through Open source Computer Vision (Open CV) which is a library of functions that aids image processing in real time. The morphological features extracted from the image are given to Neural Network Pattern Recognition Tool. This effort has been prepared to categorize the appropriate quality category for a specified rice sample based on its parameters. The performance of image processing condensed the time of action and enhanced the crop identification significantly.},
author = {Neelamegam, P and Abirami, S and {Vishnu Priya}, K and {Rubalya Valantina}, S},
doi = {10.1109/CICT.2013.6558219},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Neelamegam et al. - Analysis of rice granules using image processing and neural network - Information {\&} Communication Technologies (ICT).pdf:pdf},
journal = {Information {\&} Communication Technologies (ICT), 2013 IEEE Conference on},
keywords = {Biological neural networks,Canny edge detection,Detectors,Feature extraction,Histograms,Image edge detection,Open CV,Sobel edge detection,adaptive thresholding,basmati rice granules,classification grades,crop recognition,digital imaging,edge detection,food handling industry,food processing industry,granular food materials,gray scale,image classification,image colour analysis,image processing,image segmentation,median smoothing,neural nets,neural network,open source computer vision},
number = {7},
pages = {879--884},
title = {{Analysis of rice granules using image processing and neural network}},
volume = {96},
year = {2013}
}
@article{Nie2013,
abstract = {An automatic detector that finds circular dining plates in chronically recorded images or videos is reported for the study of food intake and obesity. We first detect edges from input images. After a number of processing steps that convert edges into curves, arc filtering and grouping algorithms are applied. Then, convex hulls are identified and the ones that fit the description of ellipses corresponding to dining plates are determined. Our experiments using real-world images indicate that this detector is highly reliable and robust even when the input images contain complex background scenes and the dining plates are severely occluded.},
author = {Nie, Jie and Wei, Zhiqiang and Jia, Wenyan and Li, Lu and Fernstrom, John D. and Sclabassi, Robert J. and Sun, Mingui},
doi = {10.1016/j.micinf.2011.07.011.Innate},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Nie et al. - Automatic Detection of Dining Plates for Image-Based Dietary Evaluation - Conf Proc IEEE Eng Med Biol Soc. 2010.pdf:pdf},
isbn = {6176321972},
journal = {Conf Proc IEEE Eng Med Biol Soc. 2010},
keywords = {computer-aided drug design,cyclophilin,free energy perturbation,hiv,reverse transcriptase},
number = {9},
pages = {1199--1216},
title = {{Automatic Detection of Dining Plates for Image-Based Dietary Evaluation}},
volume = {18},
year = {2013}
}
@article{Chen2014,
abstract = {Deep Convolutional Neural Networks (DCNNs) have recently shown state of the art performance in high level vision tasks, such as image classification and object detection. This work brings together methods from DCNNs and probabilistic graphical models for addressing the task of pixel-level classification (also called "semantic image segmentation"). We show that responses at the final layer of DCNNs are not sufficiently localized for accurate object segmentation. This is due to the very invariance properties that make DCNNs good for high level tasks. We overcome this poor localization property of deep networks by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF). Qualitatively, our "DeepLab" system is able to localize segment boundaries at a level of accuracy which is beyond previous methods. Quantitatively, our method sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 71.6{\%} IOU accuracy in the test set. We show how these results can be obtained efficiently: Careful network re-purposing and a novel application of the 'hole' algorithm from the wavelet community allow dense computation of neural net responses at 8 frames per second on a modern GPU.},
archivePrefix = {arXiv},
arxivId = {1412.7062},
author = {Chen, Liang-Chieh and Papandreou, George and Kokkinos, Iasonas and Murphy, Kevin and Yuille, Alan L.},
eprint = {1412.7062},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Chen et al. - Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs - Unknown.pdf:pdf},
month = {dec},
title = {{Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs}},
url = {http://arxiv.org/abs/1412.7062},
year = {2014}
}
@article{Bosch2014,
abstract = {Many chronic diseases, such as heart diseases, diabetes, and obesity, can be related to diet. Hence, the need to accurately measure diet becomes imperative. We are developing methods to use image analysis tools for the identification and quantification of food consumed at a meal. In this paper we describe a new approach to food identification using several features based on local and global measures and a “voting” based late decision fusion classifier to identify the food items. Experimental results on a wide variety of food items are presented. Index},
annote = {Of the 10 leading causes of death in the U.S., 6 are related to diet.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Bosch, Marc and Zhu, Fengqing and Khanna, Nitin and Boushey, Carol and Edward, Delp},
doi = {10.1016/j.drugalcdep.2008.02.002.A},
eprint = {NIHMS150003},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Bosch et al. - Combining global and local features for food identification in dietary assessment - IEEE Trans Image Process. 2011 2011.pdf:pdf},
isbn = {2156623929},
issn = {08966273},
journal = {IEEE Trans Image Process. 2011 ; 2011: 1789–1792.},
keywords = {Feature extraction,image analysis,image texture,object recognition,supervised learning},
mendeley-tags = {Feature extraction,image analysis,image texture,object recognition,supervised learning},
number = {10},
pages = {1203--1214},
pmid = {1000000221},
title = {{Combining global and local features for food identification in dietary assessment}},
volume = {15},
year = {2014}
}
@book{Theodoridis2009d,
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50020-7},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(11).pdf:pdf},
isbn = {9781597492720},
pages = {927--929},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500207},
year = {2009}
}
@article{Shotton2013,
abstract = {We propose a new method to quickly and accurately predict 3D positions of body joints from a single depth image, using no temporal information. We take an object recognition approach, designing an intermediate body parts representation that maps the difficult pose estimation problem into a simpler per-pixel classification problem. Our large and highly varied training dataset allows the classifier to estimate body parts invariant to pose, body shape, clothing, etc. Finally we generate confidence-scored 3D proposals of several body joints by reprojecting the classification result and finding local modes. The system runs at 200 frames per second on consumer hardware. Our evaluation shows high accuracy on both synthetic and real test sets, and investigates the effect of several training parameters. We achieve state of the art accuracy in our comparison with related work and demonstrate improved generalization over exact whole-skeleton nearest neighbor matching.},
author = {Shotton, Jamie and Fitzgibbon, Andrew and Cook, Mat and Sharp, Toby and Finocchio, Mark and Moore, Richard and Kipman, Alex and Blake, Andrew},
journal = {Studies in Computational Intelligence},
pages = {119--135},
title = {{Real-time human pose recognition in parts from single depth images}},
volume = {411},
year = {2013}
}
@article{Rodriguez2004,
author = {Rodriguez, Carlos C (Albany)},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2004/Rodriguez - The Kernel Trick - October.pdf:pdf},
isbn = {0262122413},
journal = {October},
number = {x},
pages = {1--5},
title = {{The Kernel Trick}},
year = {2004}
}
@misc{Kim2013,
abstract = {Data analysis of a food item based on one or more digital images of the food item is disclosed. In one embodiment, the method comprises displaying, on a display unit of the smart device, first and second digital images of a meal, where the first digital image is captured before the second digital image. The method also comprises determining a volume of each food item in the first digital image and a volume of each food item in the second digital image by analyzing the first digital image and the second digital image using a digital image processing technique. The method further comprises generating, on the display unit, an amount of intake for the meal based on a difference between the volume of each food item in the first digital image and the volume of each food item in the second digital image.},
annote = {Erkl{\"{a}}rt nicht wie die Klassifizierung funktionieren soll. {\&}quot;Image Processing{\&}quot; wird erw{\"{a}}hnt, aber nicht weiter ausgef{\"{u}}hrt.},
author = {Kim, Kyungjin and Lee, Kiwon and Cho, Sungil and Hong, Jiyoung and Kim, Sungeun},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Kim et al. - Analysis of food items captured in digital images - Unknown.pdf:pdf},
month = {dec},
title = {{Analysis of food items captured in digital images}},
url = {https://www.google.com.ar/patents/US20130335418},
year = {2013}
}
@book{Theodoridis2009h,
abstract = {This chapter discusses clustering validity stage of a clustering procedure. The chapter presents methods suitable for quantitative evaluation of the results of a clustering algorithm, known under the general term cluster validity. Cluster validity can be approached in three possible directions. First is to evaluate C (where C is the clustering structure resulting from the application of a clustering algorithm on data set X) in terms of an independently drawn structure, which is imposed on X a priori and reflects intuition about the clustering structure of X. The criteria used for the evaluation of this kind are called external criteria. External criteria may be used to measure the degree to which the available data confirm a prespecified structure, without applying any clustering algorithm to X. The criteria used for this kind of evaluation are called internal criteria. Last approach is to evaluate C by comparing it with other clustering structures, resulting from the application of the same clustering algorithm, but with different parameter values, or of other clustering algorithms to X. Criteria of this kind are called relative criteria. This chapter also focuses on the definitions of internal, external, and relative criteria and the random hypotheses used in each case. Indices, adopted in the framework of external and internal criteria, are presented, and examples are provided showing the use of these indices.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50018-9},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(6).pdf:pdf},
isbn = {9781597492720},
pages = {863--913},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500189},
year = {2009}
}
@article{Gujjar2014,
abstract = {This paper deals with the classification of bulk food grain samples and detection of foreign bodies in food grains. A new method for inspecting food samples is presented, using ANN and segmentation to classify grain samples and detect foreign bodies that are not detectable using conventional methods easily. A BPNN based classifier is designed to classify the unknown grain samples. The algorithms are developed to extract color, texture and combined features are extracted from grains and after normalization presented to neural network for training purpose. The trained network is then used to identify the unknown grain type and it's quality in terms of pure/impure type. A Segmentation based detection model is developed to detect the foreign body in the impure grain samples. This model accepts an impure grain samples, pre-processes and segments the image using two different thresholds T1 and T2 to detect the foreign body in impure image. Finally the success rates are observed from both classification and foreign body detection models and are recorded.},
author = {Gujjar, Harish S and Siddappa, M.},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Gujjar, Siddappa - Recognition and Classification of Different Types of Food Grains and Detection of Foreign Bodies using Neural Network.pdf:pdf;:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Gujjar, Siddappa - Recognition and Classification of Different Types of Food Grains and Detection of Foreign Bodies using Neural Netw(2).pdf:pdf},
journal = {IJCA Proceedings on International Conference on Information and Communication Technologies},
month = {aug},
number = {1},
pages = {12--17},
publisher = {Foundation of Computer Science (FCS)},
title = {{Recognition and Classification of Different Types of Food Grains and Detection of Foreign Bodies using Neural Networks}},
url = {http://www.ijcaonline.org/proceedings/icict/number1/17959-1403},
volume = {ICICT},
year = {2014}
}
@article{Csurka2004,
abstract = {We present a novel method for generic visual categorization: the problem of identifying the object content of natural images while generalizing across variations inherent to the object class. This bag of keypoints method is based on vector quantization of affine invariant descriptors of image patches. We propose and compare two alternative implementations using different classifiers: Na{\"{\i}}ve Bayes and SVM. The main advantages of the method are that it is simple, computationally efficient and intrinsically invariant. We present results for simultaneously classifying seven semantic visual categories. These results clearly demonstrate that the method is robust to background clutter and produces good categorization accuracy even without exploiting geometric information.},
author = {Csurka, Gabriella and Dance, Christopher R. and Fan, Lixin and Willamowski, Jutta and Bray, C{\'{e}}dric},
doi = {10.1234/12345678},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2004/Csurka et al. - Visual categorization with bags of keypoints - Proceedings of the ECCV International Workshop on Statistical Learning in.pdf:pdf},
isbn = {9780335226375},
issn = {18703453},
journal = {Proceedings of the ECCV International Workshop on Statistical Learning in Computer Vision},
pages = {59--74},
title = {{Visual categorization with bags of keypoints}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.72.604},
year = {2004}
}
@inproceedings{Khan2013,
author = {Khan, Rahat and van de Weijer, Joost and {Shahbaz Khan}, Fahad and Muselet, Damien and Ducottet, Christophe and Barat, Cecile},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Khan et al. - Discriminative Color Descriptors - Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.pdf:pdf},
pages = {2866--2873},
title = {{Discriminative Color Descriptors}},
url = {http://www.cv-foundation.org/openaccess/content{\_}cvpr{\_}2013/html/Khan{\_}Discriminative{\_}Color{\_}Descriptors{\_}2013{\_}CVPR{\_}paper.html},
year = {2013}
}
@article{Dosovitskiy2013,
abstract = {When deep learning is applied to visual object recognition, data augmentation is often used to generate additional training data without extra labeling cost. It helps to reduce overfitting and increase the performance of the algorithm. In this paper we investigate if it is possible to use data augmentation as the main component of an unsupervised feature learning architecture. To that end we sample a set of random image patches and declare each of them to be a separate single-image surrogate class. We then extend these trivial one-element classes by applying a variety of transformations to the initial 'seed' patches. Finally we train a convolutional neural network to discriminate between these surrogate classes. The feature representation learned by the network can then be used in various vision tasks. We find that this simple feature learning algorithm is surprisingly successful, achieving competitive classification results on several popular vision datasets (STL-10, CIFAR-10, Caltech-101).},
archivePrefix = {arXiv},
arxivId = {1312.5242},
author = {Dosovitskiy, Alexey and Springenberg, Jost Tobias and Brox, Thomas},
eprint = {1312.5242},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Dosovitskiy, Springenberg, Brox - Unsupervised feature learning by augmenting single images - Unknown.pdf:pdf},
month = {dec},
pages = {7},
title = {{Unsupervised feature learning by augmenting single images}},
url = {http://arxiv.org/abs/1312.5242},
year = {2013}
}
@article{Thome2012,
author = {Thome, Antonio Carlos Gay},
doi = {10.5772/2575},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Thome - SVM Classifiers – Concepts and Applications to Character Recognition - Advances in Character Recognition.pdf:pdf},
isbn = {978-953-51-0823-8},
journal = {Advances in Character Recognition},
pages = {25--49},
title = {{SVM Classifiers – Concepts and Applications to Character Recognition}},
url = {http://www.intechopen.com/books/advances-in-character-recognition},
year = {2012}
}
@misc{Bloomberg2008,
abstract = {We describe some observations on the practical implementation of the median cut color quantization algorithm, suitably modiﬁed for accurate color rendering. The RGB color space is successively divided in such a way that colors with visual signiﬁcance, even if relatively small in population, are given representatives in the colormap. Appropriately modiﬁed, median cut quantization is nearly as good as our best octree quantization. As with octree quantization, error-diffusion dithering is useful for reducing posterization in large regions with a slow variation in color.},
author = {Bloomberg, Dan S.},
keywords = {color quantisation,mmcq,modified median cut},
mendeley-tags = {color quantisation,mmcq,modified median cut},
title = {{Color quantization using modified median cut}},
url = {http://www.leptonica.com/papers/mediancut.pdf},
year = {2008}
}
@book{Theodoridis2009l,
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50019-0},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(13).pdf:pdf},
isbn = {9781597492720},
pages = {915--926},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500190},
year = {2009}
}
@article{Dieleman2015,
author = {Dieleman, Sander and Heilman, Michael and Kelly, Jack and Thoma, Martin and Rasul, Dr. Kashif and Battenberg, Eric and Weideman, Hendrik and S{\o}nderby, S{\o}ren Kaae and Instagibbs and Britefury and Raffel, Colin and Degrave, Jonas and Peterderivaz and Jon and Fauw, Jeffrey De and Diogo149 and Nouri, Daniel and Schl{\"{u}}ter, Jan and Maturana, Daniel and CongLiu and Olson, Eben and McFee, Brian and Takacsg84},
doi = {10.5281/zenodo.27878},
month = {aug},
title = {{Lasagne: First release.}},
url = {http://zenodo.org/record/27878},
year = {2015}
}
@book{Theodoridis2009p,
abstract = {This chapter introduces pattern recognition as the scientific discipline with the goal of classification of objects into a number of categories or classes. The chapter discusses the basic philosophy and methodological directions in which the various pattern recognition approaches have evolved and developed. Pattern recognition is an integral part of most machine intelligence systems built for decision making. Machine vision is an area in which pattern recognition is of importance. A typical application of a machine vision system is in the manufacturing industry, either for automated visual inspection or for automation in the assembly line. Character recognition is another important area of pattern recognition, with major implications in automation and information handling. Computer-aided diagnosis is an application of pattern recognition, aimed at assisting doctors in making diagnostic decisions. The chapter outlines various other areas in which pattern recognition finds its use. The chapter also explains the concept of supervised, unsupervised, and semisupervised learning, and concludes with a brief discussion on the contents of other chapters.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50003-7},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(5).pdf:pdf},
isbn = {9781597492720},
pages = {1--12},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500037},
year = {2009}
}
@article{Dalal2005,
abstract = {We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
archivePrefix = {arXiv},
arxivId = {chao-dyn/9411012},
author = {Dalal, Navneet and Triggs, Bill},
doi = {10.1109/CVPR.2005.177},
eprint = {9411012},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2005/Dalal, Triggs - Histograms of Oriented Gradients for Human Detection - CVPR '05 Proceedings of the 2005 IEEE Computer Society Conference.pdf:pdf},
isbn = {0-7695-2372-2},
issn = {1063-6919},
journal = {CVPR '05: Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1},
keywords = {human-detection,local-feature,object-detection},
pages = {886--893},
pmid = {9230594},
primaryClass = {chao-dyn},
title = {{Histograms of Oriented Gradients for Human Detection}},
url = {citeulike-article-id:3047126$\backslash$nhttp://dx.doi.org/10.1109/CVPR.2005.177},
year = {2005}
}
@misc{openCVWebsite,
booktitle = {2016},
title = {{ABOUT | OpenCV http://opencv.org/about.html}},
url = {http://opencv.org/about.html},
urldate = {2016-03-22}
}
@article{Calonder2010,
author = {Calonder, M. and Lepetit, V. and Strecha, C. and Fua, P.},
doi = {10.1007/978-3-642-15561-1{\_}56},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Calonder et al. - BRIEF Binary Robust Independent Elementary Features - European Conference on Computer Vision (ECCV).pdf:pdf},
isbn = {3-642-15560-X, 978-3-642-15560-4},
issn = {978-3-642-15560-4},
journal = {European Conference on Computer Vision (ECCV)},
pages = {778--792},
title = {{BRIEF : Binary Robust Independent Elementary Features}},
year = {2010}
}
@book{Swaroop,
author = {Swaroop, C H},
file = {:C$\backslash$:/Users/felix/OneDrive/Studium/Studium/7. Semester/BA/Papers/Unknown/Swaroop{\_}A Byte of Python{\_}Unknown.pdf:pdf},
title = {{A Byte of Python}},
url = {http://files.swaroopch.com/python/byte{\_}of{\_}python.pdf}
}
@article{Pouladzadeh2014,
abstract = {As people across the globe are becoming more interested in watching their weight, eating more healthy, and avoiding obesity, a system that can measure calories and nutrition in every day meals can be very useful. In this paper, we propose a food calorie and nutrition measurement system that can help patients and dietitians to measure and manage daily food intake. Our system is built on food image processing and uses nutritional fact tables. Recently, there has been an increase in the usage of personal mobile technology such as smartphones or tablets, which users carry with them practically all the time. Via a special calibration technique, our system uses the built-in camera of such mobile devices and records a photo of the food before and after eating it to measure the consumption of calorie and nutrient components. Our results show that the accuracy of our system is acceptable and it will greatly improve and facilitate current manual calorie measurement techniques.},
author = {Pouladzadeh, Parisa and Shirmohammadi, Shervin and Al-Maghrabi, Rana},
doi = {10.1109/TIM.2014.2303533},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Pouladzadeh, Shirmohammadi, Al-Maghrabi - Measuring Calorie and Nutrition From Food Image - IEEE Transactions on Instrumentation and Mea.pdf:pdf},
issn = {0018-9456},
journal = {IEEE Transactions on Instrumentation and Measurement},
keywords = {Accuracy,Calorie measurement,Feature extraction,Image color analysis,Image segmentation,Support vector machines,Thumb,Volume measurement,biomedical measurement,built-in camera,calibration,calibration technique,cameras,computerised instrumentation,food calorie measurement system,food image processing,food nutrition measurement system,food photo recording,food products,medical image processing,mobile computing,mobile device,nutritional fact tables,obesity management,obesity management.,patient treatment,personal mobile technology,volume measurement},
month = {aug},
number = {8},
pages = {1947--1956},
shorttitle = {Instrumentation and Measurement, IEEE Transactions},
title = {{Measuring Calorie and Nutrition From Food Image}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6748066},
volume = {63},
year = {2014}
}
@misc{DeFreitas2015,
annote = {Sehr gute Einf{\"{u}}hrung},
author = {de Freitas, Nando},
keywords = {AI,Artificial Intelligence (Field Of Study),convolutional networks,deep learning,machine learning,nando de freitas,neural networks},
title = {{Deep Learning Lecture 1: Introduction}},
url = {https://www.youtube.com/watch?v=PlhFWT7vAEw},
urldate = {2015-11-06},
year = {2015}
}
@book{Theodoridis2009,
abstract = {This chapter explains the basic concepts of system evaluation and semisupervised learning. The beginning sections of the chapter focus on the last stage of the design procedure of a classification system. It is assumed that an optimal classifier has been designed, based on a selected set of training feature vectors. The goal is to evaluate its performance with respect to the probability of classification error associated with the designed system. Methodologies are developed for the estimation of the classification error probability, using the available, hence finite, set of data. Techniques for feature generation, feature selection, classifier design, and system evaluation are mobilized in order to develop a realistic computer-aided diagnosis medical system to assist a doctor reaching a decision. The chapter aims to introduce semisupervised learning basics and to indicate the possible performance improvement that unlabeled data may offer if used properly. The various error rate estimation techniques are discussed, and a case study with real data is treated. The leave-one-out method and the resubstitution methods are also discussed in the chapter.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50012-8},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(21).pdf:pdf},
isbn = {9781597492720},
pages = {567--594},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500128},
year = {2009}
}
@misc{Kim2014,
abstract = {Recognition of food images is emerging as an impotant research topic in image classification problem because of the demand for dietary assessment tools. In this paper, we propose an automatic food image recognition system for 100 food categories by fusing various kinds of handcrafted image features including bag-of-features (BoF) and Fisher Vectors with SIFT and HOG descriptors. In addition, we used extracted features from Deep Convolutional Neural Network. Our experiments achieved 40.34{\%} as the top 1 accuracy and 75.34{\%} as the top 5 accuracy for the 100 class food image dataset, UEC-FOOD100, which out- performs the best classification accuracy of this dataset reported so far, 72.26{\%}, greatly.},
annote = {GitHub Repository CNN -{\&}gt; https://github.com/carpedm20/FoodClassifier},
author = {Kim, Taehoon},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Kim - Food Image Recognition Boosting with Shallow Handcrafted Feature and Deep Convolutional Feature - Unknown.pdf:pdf},
keywords = {deep convolutional,fisher vector,food recognition},
title = {{Food Image Recognition : Boosting with Shallow Handcrafted Feature and Deep Convolutional Feature}},
url = {https://drive.google.com/file/d/0ByTS2HBKYvZxeHNhbUN1UkhGWjd2RTJYRkphb3dkSjVBbjJn/view https://github.com/carpedm20/FoodClassifier https://github.com/carpedm20/FoodClas},
year = {2014}
}
@article{Martin2014,
abstract = {The digital photography of foods method accurately estimates the food intake of adults and children in cafeterias. When using this method, images of food selection and leftovers are quickly captured in the cafeteria. These images are later compared with images of 'standard' portions of food using computer software. The amount of food selected and discarded is estimated based upon this comparison, and the application automatically calculates energy and nutrient intake. In the present review, we describe this method, as well as a related method called the Remote Food Photography Method (RFPM), which relies on smartphones to estimate food intake in near real-time in free-living conditions. When using the RFPM, participants capture images of food selection and leftovers using a smartphone and these images are wirelessly transmitted in near real-time to a server for analysis. Because data are transferred and analysed in near real-time, the RFPM provides a platform for participants to quickly receive feedback about their food intake behaviour and to receive dietary recommendations for achieving weight loss and health promotion goals. The reliability and validity of measuring food intake with the RFPM in adults and children is also reviewed. In sum, the body of research reviewed demonstrates that digital imaging accurately estimates food intake in many environments and it has many advantages over other methods, including reduced participant burden, elimination of the need for participants to estimate portion size, and the incorporation of computer automation to improve the accuracy, efficiency and cost-effectiveness of the method.},
author = {Martin, C K and Nicklas, T and Gunturk, B and Correa, J B and Allen, H R and Champagne, C},
doi = {10.1111/jhn.12014},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Martin et al. - Measuring food intake with digital photography. - Journal of human nutrition and dietetics the official journal of the.pdf:pdf},
issn = {1365-277X},
journal = {Journal of human nutrition and dietetics : the official journal of the British Dietetic Association},
keywords = {Cell Phones,Computers,Diet,Diet Records,Diet Surveys,Energy Intake,Food Habits,Food Preferences,Goals,Health Promotion,Humans,Mental Recall,Molecular Sequence Data,Nutrition Assessment,Photography,Portion Size,Recommended Dietary Allowances,Remote Sensing Technology,Reproducibility of Results,Software,Surveys and Questionnaires,Weight Loss},
month = {jan},
pages = {72--81},
pmid = {23848588},
title = {{Measuring food intake with digital photography.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4138603{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {27 Suppl 1},
year = {2014}
}
@article{Ogden2010,
abstract = {CONTEXT: The prevalence of high body mass index (BMI) among children and adolescents in the United States appeared to plateau between 1999 and 2006.

OBJECTIVES: To provide the most recent estimates of high BMI among children and adolescents and high weight for recumbent length among infants and toddlers and to analyze trends in prevalence between 1999 and 2008.

DESIGN, SETTING, AND PARTICIPANTS: The National Health and Nutrition Examination Survey 2007-2008, a representative sample of the US population with measured heights and weights on 3281 children and adolescents (2 through 19 years of age) and 719 infants and toddlers (birth to 2 years of age).

MAIN OUTCOME MEASURES: Prevalence of high weight for recumbent length (> or = 95th percentile of the Centers for Disease Control and Prevention growth charts) among infants and toddlers. Prevalence of high BMI among children and adolescents defined at 3 levels: BMI for age at or above the 97th percentile, at or above the 95th percentile, and at or above the 85th percentile of the BMI-for-age growth charts. Analyses of trends by age, sex, and race/ethnicity from 1999-2000 to 2007-2008.

RESULTS: In 2007-2008, 9.5{\%} of infants and toddlers (95{\%} confidence interval [CI], 7.3{\%}-11.7{\%}) were at or above the 95th percentile of the weight-for-recumbent-length growth charts. Among children and adolescents aged 2 through 19 years, 11.9{\%} (95{\%} CI, 9.8{\%}-13.9{\%}) were at or above the 97th percentile of the BMI-for-age growth charts; 16.9{\%} (95{\%} CI, 14.1{\%}-19.6{\%}) were at or above the 95th percentile; and 31.7{\%} (95{\%} CI, 29.2{\%}-34.1{\%}) were at or above the 85th percentile of BMI for age. Prevalence estimates differed by age and by race/ethnic group. Trend analyses indicate no significant trend between 1999-2000 and 2007-2008 except at the highest BMI cut point (BMI for age > or = 97th percentile) among all 6- through 19-year-old boys (odds ratio [OR], 1.52; 95{\%} CI, 1.17-2.01) and among non-Hispanic white boys of the same age (OR, 1.87; 95{\%} CI, 1.22-2.94).

CONCLUSION: No statistically significant linear trends in high weight for recumbent length or high BMI were found over the time periods 1999-2000, 2001-2002, 2003-2004, 2005-2006, and 2007-2008 among girls and boys except among the very heaviest 6- through 19-year-old boys.},
author = {Ogden, Cynthia L and Carroll, Margaret D and Curtin, Lester R and Lamb, Molly M and Flegal, Katherine M},
doi = {10.1001/jama.2009.2012},
issn = {1538-3598},
journal = {JAMA},
keywords = {Adolescent,Adult,Body Mass Index,Child,Child, Preschool,Female,Humans,Infant,Infant, Newborn,Male,Nutrition Surveys,Overweight,Overweight: epidemiology,Prevalence,United States,United States: epidemiology,Young Adult},
month = {jan},
number = {3},
pages = {242--9},
pmid = {20071470},
publisher = {American Medical Association},
title = {{Prevalence of high body mass index in US children and adolescents, 2007-2008.}},
url = {http://jama.jamanetwork.com/article.aspx?articleid=185233},
volume = {303},
year = {2010}
}
@article{Falkenauer1998,
author = {Falkenauer, E},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1998/Falkenauer - On method overfitting - Journal of Heuristics.pdf:pdf},
issn = {13811231},
journal = {Journal of Heuristics},
keywords = {benchmarking,general and targeted methods,method applicability,optimization,overfitting},
pages = {1--6},
title = {{On method overfitting}},
url = {http://link.springer.com/article/10.1023/A:1009617801681},
volume = {287},
year = {1998}
}
@article{Prabu2015,
abstract = {Computer vision-based food recognition could be used to estimate a meal’s carbohydrate content for diabetic patients. This study proposes a methodology for automatic food recognition, based on the bag-of-features (BoF) model,GLCM and LBP features. Moreover, the enhancement of the visual dataset with more images will improve the classification rates, especially for the classes with high diversity. The final system will additionally include a food segmentation stage before applying the proposed recognition module, so that images with multiple food types can also be addressed. The optimized system computes dense local features, using the scaleinvariant feature transform on the HSV color space and texture features and these extracted features are trained and classified using SVM classifier. The system achieved classification accuracy of the order of 90{\%}, thus proving the feasibility of the proposed approach in a very challenging image dataset.},
author = {Prabu, K Ganesh},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Prabu - A Food Recognition System for Diabetic Patients using SVM Classifier - International Journal of Advanced Technology in Engineeri.pdf:pdf},
journal = {International Journal of Advanced Technology in Engineering and Science},
keywords = {diabetic patients,optimized system,recognition module,texture features},
number = {2},
pages = {371--378},
title = {{A Food Recognition System for Diabetic Patients using SVM Classifier}},
url = {http://ijates.com/images/short{\_}pdf/1422098038{\_}401.pdf},
volume = {3},
year = {2015}
}
@article{Kawano2014a,
abstract = {We propose a mobile food recognition system the purposes of which are estimating calorie and nutritious of foods and recording a user's eating habits. Since all the processes on image recognition performed on a smartphone, the system does not need to send images to a server and runs on an ordinary smartphone in a real-time way. To recognize food items, a user draws bounding boxes by touching the screen first, and then the system starts food item recognition within the indicated bounding boxes. To recognize them more accurately, we segment each food item region by GrubCut, extract a color histogram and SURF-based bag-of-features, and finally classify it into one of the fifty food categories with linear SVM and fast chi(2) kernel. In addition, the system estimates the direction of food regions where the higher SVM output score is expected to be obtained, show it as an arrow on the screen in order to ask a user to move a smartphone camera. This recognition process is performed repeatedly about once a second. We implemented this system as an Android smartphone application so as to use multiple CPU cores effectively for real-time recognition. In the experiments, we have achieved the 81.55{\%} classification rate for the top 5 category candidates when the ground-truth bounding boxes are given. In addition, we obtained positive evaluation by user study compared to the food recording system without object recognition.},
author = {Kawano, Yoshiyuki and Yanai, Keiji},
doi = {10.1007/978-3-319-04117-9{\_}38},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Kawano, Yanai - FoodCam A real-time mobile food recognition system employing Fisher Vector - Lecture Notes in Computer Science (includin.pdf:pdf},
isbn = {9783319041162},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
number = {PART 2},
pages = {369--373},
title = {{FoodCam: A real-time mobile food recognition system employing Fisher Vector}},
volume = {8326 LNCS},
year = {2014}
}
@article{Leung2001,
abstract = {We study the recognition of surfaces made from different materials such as concrete, rug, marble, or leather on the basis of their textural appearance. Such natural textures arise from spatial variation of two surface attributes: (1) reflectance and (2) surface normal. In this paper, we provide a unified model to address both these aspects of natural texture. The main idea is to construct a vocabulary of prototype tiny surface patches with associated local geometric and photometric properties. We call these 3D textons . Examples might be ridges, grooves, spots or stripes or combinations thereof. Associated with each texton is an appearance vector , which characterizes the local irradiance distribution, represented as a set of linear Gaussian derivative filter outputs, under different lighting and viewing conditions.},
author = {Leung, Thomas and Malik, Jitendra},
doi = {10.1023/A:1011126920638},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2001/Leung, Malik - Representing and recognizing the visual appearance of materials using three-dimensional textons - International Journal o.pdf:pdf},
isbn = {0920-5691},
issn = {09205691},
journal = {International Journal of Computer Vision},
keywords = {3D texture,Natural material recognition,Texture recognition,Texture synthesis},
number = {1},
pages = {29--44},
pmid = {21126719},
title = {{Representing and recognizing the visual appearance of materials using three-dimensional textons}},
volume = {43},
year = {2001}
}
@article{Kawano2015,
abstract = {In this paper, we propose a novel effective framework to ex-pand an existing image dataset automatically leveraging existing cat-egories and crowdsourcing. Especially, in this paper, we focus on ex-pansion on food image data set. The number of food categories is un-countable, since foods are different from a place to a place. If we have a Japanese food dataset, it does not help build a French food recognition system directly. That is why food data sets for different food cultures have been built independently category so far. Then, in this paper, we propose to leverage existing knowledge on food of other cultures by a generic " foodness " classifier and domain adaptation. This can enable us not only to built other-cultured food datasets based on an original food image dataset automatically, but also to save as much crowd-sourcing costs as possible. In the experiments, we show the effectiveness of the proposed method over the baselines.},
annote = {UEC FOOD 256},
author = {Kawano, Yoshiyuki and Yanai, Keiji},
doi = {10.1007/978-3-319-16199-0{\_}1},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Kawano, Yanai - Automatic expansion of a food image dataset leveraging existing categories with domain adaptation - Lecture Notes in Com.pdf:pdf},
isbn = {9783319161983},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Adaptive SVM,Crowd-sourcing,Dataset expansion,Domain adaptation,Food image,Foodness},
pages = {3--17},
title = {{Automatic expansion of a food image dataset leveraging existing categories with domain adaptation}},
volume = {8927},
year = {2015}
}
@misc{WHO,
abstract = {Obesity fact sheet from WHO providing key facts and information on causes, health consequences, double burden of disease, prevention, WHO response.},
author = {{World Health Organization}},
booktitle = {Fact sheet N°311},
publisher = {World Health Organization},
title = {{WHO | Obesity and overweight}},
url = {http://www.who.int/mediacentre/factsheets/fs311/en/},
urldate = {2016-03-30},
year = {2015}
}
@article{Bay2006,
abstract = {Abstract. In this paper, we present a novel scale- and rotation-invariant interest point detector and descriptor, coined SURF (Speeded Up Ro- bust Features). It approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (in casu, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper presents experimental results on a standard evaluation set, as well as on imagery obtained in the context of a real-life object recognition application. Both show SURF’s strong performance.},
author = {Bay, H. and Tuytelaars, T. and {Van Gool}, L.},
doi = {10.1007/11744023{\_}32},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2006/Bay, Tuytelaars, Van Gool - Speeded up robust features - Lecture notes in computer science.pdf:pdf},
isbn = {3540338322},
issn = {03029743},
journal = {Lecture notes in computer science},
pages = {14},
pmid = {16081019},
title = {{Speeded up robust features}},
url = {http://www.springerlink.com/index/e580h2k58434p02k.pdf},
volume = {3951},
year = {2006}
}
@article{Chen2001,
abstract = {With multiresolution decomposition and forest representation of wavelet transforms, we implemented a “from presence to classification” object-detection model. Three aspects of this model are studied. First, the presence of an object is quickly detected with fewer data manipulations at the coarsest resolution; secondly, object classification with high accuracy is fulfilled at the full resolution; and thirdly, the propagation in the coarse-to-fine process is studied in terms of coefficient propagation within a coefficient tree. We applied this model to internal deboned poultry inspection. As soon as the presence of a hazardous object was detected at a coarse resolution, a signal was actuated to reject the chicken fillet containing foreign inclusions before packing. Only with small foreign inclusions did we need to resort to finer resolution analysis.},
author = {Chen, Zikuan and Tao, Yang},
doi = {10.1016/S0031-3203(00)00169-2},
file = {::},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {Food safety,Forest representation,Multiresolution analysis,Object recognition,Wavelet transform},
month = {dec},
number = {12},
pages = {2331--2338},
title = {{Food safety inspection using “from presence to classification” object-detection model}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320300001692},
volume = {34},
year = {2001}
}
@article{Gehler2009,
abstract = {A key ingredient in the design of visual object classification systems is the identification of relevant class specific aspects while being robust to intra-class variations. While this is a necessity in order to generalize beyond a given set of training images, it is also a very difficult problem due to the high variability of visual appearance within each class. In the last years substantial performance gains on challenging benchmark datasets have been reported in the literature. This progress can be attributed to two developments: the design of highly discriminative and robust image features and the combination of multiple complementary features based on different aspects such as shape, color or texture. In this paper we study several models that aim at learning the correct weighting of different features from training data. These include multiple kernel learning as well as simple baseline methods. Furthermore we derive ensemble methods inspired by Boosting which are easily extendable to several multiclass setting. All methods are thoroughly evaluated on object classification datasets using a multitude of feature descriptors. The key results are that even very simple baseline methods, that are orders of magnitude faster than learning techniques are highly competitive with multiple kernel learning. Furthermore the Boosting type methods are found to produce consistently better results in all experiments. We provide insight of when combination methods can be expected to work and how the benefit of complementary features can be exploited most efficiently.},
author = {Gehler, Peter and Nowozin, Sebastian},
doi = {10.1109/ICCV.2009.5459169},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Gehler, Nowozin - On feature combination for multiclass object classification - Computer Vision, 2009 IEEE 12th International Conference.pdf:pdf},
isbn = {978-1-4244-4420-5},
issn = {1550-5499},
journal = {Computer Vision, 2009 IEEE 12th International Conference on},
number = {Iccv},
pages = {221--228},
title = {{On feature combination for multiclass object classification}},
year = {2009}
}
@misc{Lowe2004a,
abstract = {A method and apparatus for identifying scale invariant features in an image and a further method and apparatus for using such scale invariant features to locate an object in an image are disclosed. The method and apparatus for identifying scale invariant features may involve the use of a processor circuit for producing a plurality of component subregion descriptors for each subregion of a pixel region about pixel amplitude extrema in a plurality of difference images produced from the image. This may involve producing a plurality of difference images by blurring an initial image to produce a blurred image and by subtracting the blurred image from the initial image to produce the difference image. For each difference image, pixel amplitude extrema are located and a corresponding pixel region is defined about each pixel amplitude extremum. Each pixel region is divided into subregions and a plurality of component subregion descriptors are produced for each subregion. These component subregion descriptors are correlated with component subregion descriptors of an image under consideration and an object is indicated as being detected when a sufficient number of component subregion descriptors (scale invariant features) define an aggregate correlation exceeding a threshold correlation with component subregion descriptors (scale invariant features) associated with the object.},
author = {Lowe, David G.},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2004/Lowe - Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image - Un.pdf:pdf},
number = {12},
title = {{Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image}},
volume = {1},
year = {2004}
}
@book{Theodoridis2009o,
abstract = {This chapter discusses the concepts of sequential clustering algorithms and the clustering schemes and criteria that are available to the analyst. This chapter begins with a general overview of the various clustering algorithmic schemes and then focuses on one category, known as sequential algorithms. Clustering algorithms may be viewed as schemes that provide with sensible clustering by considering only a small fraction of the set containing all possible partitions of X. The result depends on the specific algorithm and the criteria used. A clustering algorithm is a learning procedure that tries to identify the specific characteristics of the clusters underlying the data set. Sequential clustering algorithms produce a single clustering and are quite straightforward and fast methods. In most of them, all the feature vectors are presented to the algorithm once or a few times (typically no more than five or six times). The final result is, usually, dependent on the order in which the vectors are presented to the algorithm. These schemes tend to produce compact and hyperspherically or hyperellipsoidally shaped clusters, depending on the distance metric used. The chapter also discusses different categories of clustering algorithms including hierarchical clustering algorithms, clustering algorithms based on cost function optimization, branch and bound clustering algorithms, genetic clustering algorithms, and stochastic relaxation methods.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50014-1},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(8).pdf:pdf},
isbn = {9781597492720},
pages = {627--652},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500141},
year = {2009}
}
@book{Bishop2006,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M},
booktitle = {Pattern Recognition},
chapter = {Graphical},
doi = {10.1117/1.2819119},
editor = {Jordan, M and Kleinberg, J and Sch{\"{o}}lkopf, B},
eprint = {0-387-31073-8},
isbn = {9780387310732},
issn = {10179909},
number = {4},
pages = {738},
pmid = {8943268},
publisher = {Springer},
series = {Information science and statistics},
title = {{Pattern Recognition and Machine Learning}},
url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}
@article{Chen2012,
abstract = {Computer-aided food identification and quantity estimation have caught more attention than before due to the growing concern of health and obesity. The identification problem is usually defined as an image categorization or classification problem and several researches on this topic have been proposed. In this paper, we address the issues of feature descriptors in the food identification problem and introduce a preliminary approach for the quantity es- timation using depth information. Sparse coding is utilized in the SIFT and Local binary pattern feature descriptors, and these fea- tures combined with Gabor and color features are used to represent food items. A multi-label SVM classifier is trained for each fea- ture, and these classifiers are combined with multi-class Adaboost algorithm. For evaluation, 50 major categories of worldwide food are used, and each category contains 100 photographs from differ- ent sources, such as photos taken manually or from Internet web albums. An overall accuracy of 68.3{\%} is achieved, and success at top-N candidates achieved 80.6{\%}, 84.8{\%}, and 90.9{\%} accuracy accordingly when N equals 2, 3, and 5, thus making mobile appli- cation practical. The experimental results show that the proposed methods greatly improve the performance of original SIFT and LBP feature descriptors. On the other hand, for quantity estimation us- ing depth information, a straight forward method is proposed for certain food, while transparent food ingredients such as pure water and},
annote = {50-data},
author = {Chen, MY and Yang, YH and Ho, CJ and Wang, SH},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Chen et al. - Automatic chinese food identification and quantity estimation - SIGGRAPH Asia 2012 {\ldots}.pdf:pdf},
journal = {SIGGRAPH Asia 2012 {\ldots}},
keywords = {Adaboost algorithm},
mendeley-tags = {Adaboost algorithm},
title = {{Automatic chinese food identification and quantity estimation}},
url = {http://dl.acm.org/citation.cfm?id=2407775},
year = {2012}
}
@article{Livingstone2007,
author = {Livingstone, M. B. E. and Robson, P. J. and Wallace, J. M. W.},
doi = {10.1079/BJN20041169},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2007/Livingstone, Robson, Wallace - Issues in dietary intake assessment of children and adolescents - British Journal of Nutrition.pdf:pdf},
issn = {0007-1145},
journal = {British Journal of Nutrition},
keywords = {Adolescents,Children,Dietary assessment},
language = {English},
month = {mar},
number = {S2},
pages = {S213},
publisher = {Cambridge University Press},
title = {{Issues in dietary intake assessment of children and adolescents}},
url = {http://journals.cambridge.org/abstract{\_}S0007114504002326},
volume = {92},
year = {2007}
}
@article{Rosten2006,
abstract = {Where feature points are used in real-time frame-rate applications, a high-speed feature detector is necessary. Feature detectors such as SIFT (DoG), Harris and SUSAN are good methods which yield high quality features, however they are too computationally intensive for use in real-time applications of any complexity. Here we show that machine learning can be used to derive a feature detector which can fully process live PAL video using less than 7{\%} of the available processing time. By comparison neither the Harris detector (120{\%}) nor the detection stage of SIFT (300{\%}) can operate at full frame rate. Clearly a high-speed detector is of limited use if the features produced are unsuitable for downstream processing. In particular, the same scene viewed from two different positions should yield features which correspond to the same real-world 3D locations [1]. Hence the second contribution of this paper is a comparison corner detectors based on this criterion applied to 3D scenes. This comparison supports a number of claims made elsewhere concerning existing corner detectors. Further, contrary to our initial expectations, we show that despite being principally constructed for speed, our detector significantly outperforms existing feature detectors according to this criterion.},
author = {Rosten, Edward and Drummond, Tom},
doi = {10.1007/11744023{\_}34},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2006/Rosten, Drummond - Machine learning for high-speed corner detection - Lecture Notes in Computer Science (including subseries Lecture Not.pdf:pdf},
isbn = {3540338322},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {430--443},
pmid = {18684738},
title = {{Machine learning for high-speed corner detection}},
volume = {3951 LNCS},
year = {2006}
}
@book{Theodoridis2009b,
abstract = {This chapter explores classifiers based on Bayes Decision Theory. The chapter primarily focuses on Bayesian classification and techniques for estimating unknown probability density functions based on the available experimental evidence. The chapter also deals with the design of the classifier in a pattern recognition system. While discussing the concept of minimizing the classification error probability, it is shown that the Bayesian classifier is optimal with respect to minimizing the classification error probability. Special focus is put on the Bayesian classification, the minimum distance (Euclidean and Mahalanobis), the nearest neighbor classifiers, and the naive Bayes classifier. The chapter approaches the classification problem via Bayesian probabilistic arguments with a goal to minimize the classification error probability or the risk. Examples are presented to show that not all problems are well suited to such approaches, and in those cases, it may be preferable to compute decision surfaces directly by means of alternative costs. The chapter also focuses on a particular family of decision surfaces associated with the Bayesian classification for the specific case of Gaussian density functions.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50004-9},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(17).pdf:pdf},
isbn = {9781597492720},
pages = {13--89},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500049},
year = {2009}
}
@article{Kitamura2009,
abstract = {With the increase of the number of food images on the Internet, we have been developing a food-logging system which has an automated analysis function as a Web application. It can distinguish food images from other images, analyze the food balance, and visualize the log. In this paper, we demonstrate how the performance can be improved by the personalized models. Because our Web application has an interface to review and correct the food analysis results, the generation of the personalized models can be done on-line. Experimental results using two hundred images showed that the extracted image feature vectors differ from user to user but on the other hand the feature vectors and the food balance of each user have a strong correlation. Therefore, the accuracy of the food balance estimation was improved from 37{\%} to 42{\%} on average by the personalized classifier. Copyright 2009 ACM.},
author = {Kitamura, Keigo and Yamasaki, Toshihiko and Aizawa, Kiyoharu},
doi = {10.1145/1630995.1631001},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Kitamura, Yamasaki, Aizawa - FoodLog Capture, Analysis and Retrieval of Personal Food Images via Web - Proceedings of the ACM multimedia.pdf:pdf},
isbn = {9781605587639},
journal = {Proceedings of the ACM multimedia 2009 workshop on Multimedia for cooking and eating activities - CEA '09},
keywords = {Food,Life-log,Multimedia interfaces},
pages = {23},
title = {{FoodLog: Capture, Analysis and Retrieval of Personal Food Images via Web}},
url = {http://portal.acm.org/citation.cfm?doid=1630995.1631001},
year = {2009}
}
@article{He2015,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learn- ing residual functions with reference to the layer inputs, in- stead of learning unreferenced functions. We provide com- prehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8× deeper than VGG nets [41] but still having lower complex- ity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our ex- tremely deep representations, we obtain a 28{\%} relative im- provement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet local- ization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
doi = {10.3389/fpsyg.2013.00124},
eprint = {1512.03385},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/He et al. - Deep Residual Learning for Image Recognition - Arxiv.Org.pdf:pdf},
isbn = {978-1-4673-6964-0},
issn = {1664-1078},
journal = {Arxiv.Org},
keywords = {deep learning,denoising auto-encoder,image denoising},
number = {3},
pages = {171--180},
pmid = {23554596},
title = {{Deep Residual Learning for Image Recognition}},
volume = {7},
year = {2015}
}
@article{Rublee2011,
author = {Rublee, Ethan and Bradski, Gary},
doi = {10.1109/ICCV.2011.6126544},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2011/Rublee, Bradski - ORB - an efficient alternative to SIFT or SURF - Unknown.pdf‎:pdf‎},
isbn = {978-1-4577-1102-2},
issn = {1550-5499},
keywords = {Ethan Rublee Vincent Rabaud Kurt Konolige Gary Bra},
pmid = {20033598},
title = {{ORB - an efficient alternative to SIFT or SURF}},
url = {http://www.willowgarage.com/sites/default/files/orb{\_}final.pdf},
year = {2011}
}
@article{Wen2009,
abstract = {Accurate and passive acquisition of dietary data from patients is essential for a better understanding of the etiology of obesity and development of effective weight management programs. Self-reporting is currently the main method for such data acquisition. However, studies have shown that data obtained by self-reporting seriously underestimate food intake and thus do not accurately reflect the real habitual behavior of individuals. Computer food recognition programs have not yet been developed. In this paper, we present a study for recognizing foods from videos of eating, which are directly recorded in restaurants by a web camera. From recognition results, our method then estimates food calories of intake. We have evaluated our method on a database of 101 foods from 9 food restaurants in USA and obtained promising results.},
author = {Wen, Wu and Jie, Yang},
doi = {10.1109/ICME.2009.5202718},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Wen, Jie - Fast food recognition from videos of eating for calorie estimation - Proceedings - 2009 IEEE International Conference on Mult.pdf:pdf},
isbn = {9781424442911},
issn = {1945-7871},
journal = {Proceedings - 2009 IEEE International Conference on Multimedia and Expo, ICME 2009},
keywords = {Calorie estimation,Fast food recognition},
pages = {1210--1213},
title = {{Fast food recognition from videos of eating for calorie estimation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.186.9475{\&}rep=rep1{\&}type=pdf},
year = {2009}
}
@article{Lawrence1996,
abstract = {One of the most important aspects of any machine learning paradigm is how it scales according to problem size and complexity. Using a task with known optimal training error, and a pre-specified maximum number of training updates, we investigate the convergence of the backpropagation algorithm with respect to a) the complexity of the required function approximation, b) the size of the network in relation to the size required for an optimal solution, and c) the degree of noise in the training data. In general, for a) the solution found is worse when the function to be approximated is more complex, for b) oversize networks can result in lower training and generalization error, and for c) the use of committee or ensemble techniques can be more beneficial as the amount of noise in the training data is increased. For the experiments we performed, we do not obtain the optimal solution in any case. We further support the observation that larger networks can produce better training and generalization error using a face recognition example where a network with many more parameters than training points generalizes better than smaller networks.},
author = {Lawrence, Steve and Giles, C Lee and Tsoi, Ah Chung},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1996/Lawrence, Giles, Tsoi - What Size Neural Network Gives Optimal Generalization Convergence Properties of Backpropagation - Networks.pdf:pdf},
journal = {Networks},
keywords = {backpropagation,committees,convergence,curse of dimensionality,ensembles,function approximation,generalization,local minima,network size,problem complexity,smoothness},
number = {UMIACS-TR-96-22 and CS-TR-3617},
pages = {1--37},
title = {{What Size Neural Network Gives Optimal Generalization ? Convergence Properties of Backpropagation}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:What+Size+Neural+Network+Gives+Optimal+Generalization?+Convergence+Properties+of+Backpropagation{\#}0},
year = {1996}
}
@article{Matsuda2013,
abstract = {In this paper, we propose a method to recog- nize food images which include multiple food items considering co-occurrence statistics of food items. Theproposedmethodemploys amanifold rank- ing method which has been applied to image re- trieval successfully in the literature. In the exper- iments, we prepared co-occurrence matrices of 100 food items using various kinds of data sources in- cludingWeb texts, Web food blogs and our own food database, and evaluated the final results obtained by applying manifold ranking. As results, it has been proved that co-occurrence statistics obtained from a food photo database is very helpful to improve the classification rate within the top ten candidates.},
author = {Matsuda, Yuji and Yanai, Keiji},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Matsuda, Yanai - Multiple-Food Image Recognition Considering Co-occurrence - International Conference on Pattern Recognition.pdf:pdf},
isbn = {9784990644116},
journal = {International Conference on Pattern Recognition},
number = {Icpr},
pages = {1724--1730},
title = {{Multiple-Food Image Recognition Considering Co-occurrence}},
year = {2013}
}
@article{Bergstra2012,
abstract = {Grid search and manual search are the most widely used strategies for hyper-parameter optimiza- tion. This paper shows empirically and theoretically that randomly chosen trials are more efficient for hyper-parameter optimization than trials on a grid. Empirical evidence comes from a compar- ison with a large previous study that used grid search and manual search to configure neural net- works and deep belief networks. Compared with neural networks configured by a pure grid search, we find that random search over the same domain is able to find models that are as good or better within a small fraction of the computation time. Granting random search the same computational budget, random search finds better models by effectively searching a larger, less promising con- figuration space. Compared with deep belief networks configured by a thoughtful combination of manual search and grid search, purely random search over the same 32-dimensional configuration space found statistically equal performance on four of seven data sets, and superior performance on one of seven. A Gaussian process analysis of the function from hyper-parameters to validation set performance reveals that for most data sets only a few of the hyper-parameters really matter, but that different hyper-parameters are important on different data sets. This phenomenon makes grid search a poor choice for configuring algorithms for new data sets. Our analysis casts some light on why recent “High Throughput”methods achieve surprising success—they appear to search through a large number of hyper-parameters because most hyper-parameters do not matter much. We anticipate that growing interest in large hierarchical models will place an increasing burden on techniques for hyper-parameter optimization; this work shows that randomsearch is a natural base- line against which to judge progress in the development of adaptive (sequential) hyper-parameter optimization algorithms.},
author = {Bergstra, James and Bengio, Yoshua},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Bergstra, Bengio - Random Search for Hyper-Parameter Optimization - Journal of Machine Learning Research.pdf:pdf},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,global optimization,model selection,neural networks,response surface},
pages = {281--305},
title = {{Random Search for Hyper-Parameter Optimization}},
volume = {13},
year = {2012}
}
@book{Theodoridis2009s,
abstract = {This chapter explores the template matching. Template matching involves defining a measure or a cost to find the “similarity” between the (known) reference patterns and the (unknown) test pattern by performing the matching operation. It finds its application in speech recognition, in automation using robot vision, in motion estimation for video coding, and in image database retrieval systems. The chapter explores the problem of string pattern matching and then deals with the scene analysis and shape recognition problems. The tasks, although they share the same goal, require different tools because of their different nature. Measures based on optimal path searching techniques and measures based on correlation are discussed. One section discusses a category of template matching, where the involved patterns consist of strings of identified symbols or feature vectors (string patterns). Topics of deformable template model and content-based information retrieval are discussed. Dynamic programming and the Viterbi algorithm are presented in the chapter and then applied to speech recognition. Correlation matching and the basic philosophy behind deformable template matching are also presented.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50010-4},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(16).pdf:pdf},
isbn = {9781597492720},
pages = {481--519},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500104},
year = {2009}
}
@inproceedings{Almaghrabi2012,
abstract = {In this paper, a food nutrition and energy intake recognition system for medical purposes is proposed. This system is built based on food image processing and shape recognition in addition to nutritional fact tables. Recently, countless studies suggested that the usage of technology such as smartphones may enhance the treatments for obesity and overweight patients. Via a special technique, the system records a photo of the food before and after eating in order to estimate the consumption calorie of the selected food and its nutrients components. Our system presents a new instrument in food intake measuring systems which can be useful and effective in obesity management.},
author = {Almaghrabi, Rana and Villalobos, Gregorio and Pouladzadeh, Parisa and Shirmohammadi, Shervin},
booktitle = {2012 IEEE International Instrumentation and Measurement Technology Conference Proceedings},
doi = {10.1109/I2MTC.2012.6229581},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Almaghrabi et al. - A novel method for measuring nutrition intake based on food image - 2012 IEEE International Instrumentation and Meas.pdf:pdf},
isbn = {978-1-4577-1772-7},
issn = {1091-5281},
keywords = {Calories measurement,Databases,Image processing,Image recognition,Obesity,Shape,Shape recognition,Support vector machines,Thumb,Volume Estimation,consumption calorie,energy intake recognition system,food image processing,food technology,image recognition,medical image processing,nutrition intake measuring,obesity,obesity management,overweight patients,shape recognition,smartphones},
language = {English},
mendeley-tags = {Volume Estimation},
month = {may},
pages = {366--370},
publisher = {IEEE},
title = {{A novel method for measuring nutrition intake based on food image}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=6229581},
year = {2012}
}
@article{Burke2011,
abstract = {Self-monitoring is the centerpiece of behavioral weight loss intervention programs. This article presents a systematic review of the literature on three components of self-monitoring in behavioral weight loss studies: diet, exercise, and self-weighing. This review included articles that were published between 1993 and 2009 that reported on the relationship between weight loss and these self-monitoring strategies. Of the 22 studies identified, 15 focused on dietary self-monitoring, one on self-monitoring exercise, and six on self-weighing. A wide array of methods was used to perform self-monitoring; the paper diary was used most often. Adherence to self-monitoring was reported most frequently as the number of diaries completed or the frequency of log-ins or reported weights. The use of technology, which included the Internet, personal digital assistants, and electronic digital scales were reported in five studies. Descriptive designs were used in the earlier studies whereas more recent reports involved prospective studies and randomized trials that examined the effect of self-monitoring on weight loss. A significant association between self-monitoring and weight loss was consistently found; however, the level of evidence was weak because of methodologic limitations. The most significant limitations of the reviewed studies were the homogenous samples and reliance on self-report. In all but two studies, the samples were predominantly white and women. This review highlights the need for studies in more diverse populations, for objective measures of adherence to self-monitoring, and for studies that establish the required dose of self-monitoring for successful outcomes.},
author = {Burke, Lora E. and Wang, Jing and Sevick, Mary Ann},
doi = {10.1016/j.jada.2010.10.008},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2011/Burke, Wang, Sevick - Self-Monitoring in Weight Loss A Systematic Review of the Literature - Journal of the American Dietetic Associatio.pdf:pdf},
issn = {00028223},
journal = {Journal of the American Dietetic Association},
keywords = {Behavior Therapy,Combined Modality Therapy,Computers, Handheld,Diet, Reducing,Diet, Reducing: psychology,Exercise,Exercise: psychology,Humans,Internet,Obesity,Obesity: psychology,Obesity: therapy,Patient Compliance,Patient Compliance: psychology,Self Care,Self Care: psychology,Weight Loss},
month = {jan},
number = {1},
pages = {92--102},
pmid = {21185970},
title = {{Self-Monitoring in Weight Loss: A Systematic Review of the Literature}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3268700{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {111},
year = {2011}
}
@book{Theodoridis2009c,
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50022-0},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition.pdf:pdf},
isbn = {9781597492720},
keywords = {Appendix},
mendeley-tags = {Appendix},
pages = {946--948},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500220},
year = {2009}
}
@inproceedings{Lowe1999,
abstract = {An object recognition system has been developed that uses a new class of local image features. The features are invariant to image scaling, translation, and rotation, and partially invariant to illumination changes and affine or 3D projection. These features share similar properties with neurons in inferior temporal cortex that are used for object recognition in primate vision. Features are efficiently detected through a staged filtering approach that identifies stable points in scale space. Image keys are created that allow for local geometric deformations by representing blurred image gradients in multiple orientation planes and at multiple scales. The keys are used as input to a nearest neighbor indexing method that identifies candidate object matches. Final verification of each match is achieved by finding a low residual least squares solution for the unknown model parameters. Experimental results show that robust object recognition can be achieved in cluttered partially occluded images with a computation time of under 2 seconds},
archivePrefix = {arXiv},
arxivId = {cs/0112017},
author = {Lowe, David G.},
booktitle = {Proceedings of the Seventh IEEE International Conference on Computer Vision},
doi = {10.1109/ICCV.1999.790410},
eprint = {0112017},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1999/Lowe - Object recognition from local scale-invariant features - Proceedings of the Seventh IEEE International Conference on Computer Vis.pdf:pdf},
isbn = {0-7695-0164-8},
issn = {0-7695-0164-8},
number = {[8},
pages = {1150--1157},
pmid = {15806121},
primaryClass = {cs},
publisher = {IEEE},
title = {{Object recognition from local scale-invariant features}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=790410},
volume = {2},
year = {1999}
}
@article{Hinton2012,
abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
archivePrefix = {arXiv},
arxivId = {1207.0580},
author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
eprint = {1207.0580},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Hinton et al. - Improving neural networks by preventing co-adaptation of feature detectors - Unknown.pdf:pdf},
keywords = {dropout},
mendeley-tags = {dropout},
month = {jul},
title = {{Improving neural networks by preventing co-adaptation of feature detectors}},
url = {http://arxiv.org/abs/1207.0580},
year = {2012}
}
@article{Foroni2013,
abstract = {In recent years we have witnessed an increasing interest in food processing and eating behaviors. This is probably due to several reasons. The biological relevance of food choices, the complexity of the food-rich environment in which we presently live (making food-intake regulation difficult), and the increasing health care cost due to illness associated with food (food hazards, food contamination, and aberrant food-intake). Despite the importance of the issues and the relevance of this research, comprehensive and validated databases of stimuli are rather limited, outdated, or not available for non-commercial purposes to independent researchers who aim at developing their own research program. The FoodCast Research Image Database (FRIDa) we present here includes 877 images belonging to eight different categories: natural-food (e.g., strawberry), transformed-food (e.g., french fries), rotten-food (e.g., moldy banana), natural-non-food items (e.g., pinecone), artificial food-related objects (e.g., teacup), artificial objects (e.g., guitar), animals (e.g., camel), and scenes (e.g., airport). FRIDa has been validated on a sample of healthy participants (N = 73) on standard variables (e.g., valence, familiarity, etc.) as well as on other variables specifically related to food items (e.g., perceived calorie content); it also includes data on the visual features of the stimuli (e.g., brightness, high frequency power, etc.). FRIDa is a well-controlled, flexible, validated, and freely available (http://foodcast.sissa.it/neuroscience/) tool for researchers in a wide range of academic fields and industry.},
author = {Foroni, Francesco and Pergola, Giulio and Argiris, Georgette and Rumiati, Raffaella I},
doi = {10.3389/fnhum.2013.00051},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Foroni et al. - The FoodCast research image database (FRIDa). - Frontiers in human neuroscience.pdf:pdf},
isbn = {1662-5161 (Electronic)$\backslash$r1662-5161 (Linking)},
issn = {1662-5161},
journal = {Frontiers in human neuroscience},
keywords = {and to avoid poisoned,category specificity,database,food,food processing,frida,humans need to process,information about,like other animals,or uneat-,possible sources of nutrition,the foodcast research image,validated images database},
number = {March},
pages = {51},
pmid = {23459781},
title = {{The FoodCast research image database (FRIDa).}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3585434{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@article{Krizhevsky2009,
abstract = {Groups at MIT and NYU have collected a dataset of millions of tiny colour images from the web. It is, in principle, an excellent dataset for unsupervised training of deep generative models, but previous researchers who have tried this have found it difficult to learn a good set of filters from the images. We show how to train a multi-layer generative model that learns to extract meaningful features which resemble those found in the human visual cortex. Using a novel parallelization algorithm to distribute the work among multiple machines connected on a network, we show how training such a model can be done in reasonable time. A second problematic aspect of the tiny images dataset is that there are no reliable class labels which makes it hard to use for object recognition experiments. We created two sets of reliable labels. The CIFAR-10 set has 6000 examples of each of 10 classes and the CIFAR-100 set has 600 examples of each of 100 non-overlapping classes. Using these labels, we show that object recognition is significantly improved by pre-training a layer of features on a large set of unlabeled tiny images.},
author = {Krizhevsky, Alex},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Krizhevsky - Learning Multiple Layers of Features from Tiny Images - {\ldots} Science Department, University of Toronto, Tech. {\ldots}.pdf:pdf},
journal = {{\ldots} Science Department, University of Toronto, Tech. {\ldots}},
pages = {1--60},
title = {{Learning Multiple Layers of Features from Tiny Images}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Learning+Multiple+Layers+of+Features+from+Tiny+Images{\#}0},
year = {2009}
}
@article{Krizhevsky2012,
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
eprint = {1102.0183},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Krizhevsky, Sutskever, Hinton - Imagenet classification with deep convolutional neural networks - Advances in neural information process.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances in neural information processing systems},
pages = {1097--1105},
title = {{Imagenet classification with deep convolutional neural networks}},
year = {2012}
}
@article{Farinella2014,
abstract = {It is well-known that people love food. However, an insane diet can cause problems in the general health of the people. Since health is strictly linked to the diet, advanced computer vision tools to recognize food images (e.g. acquired with mobile/wearable cameras), as well as their properties (e.g., calories), can help the diet monitoring by providing useful information to the experts (e.g., nutritionists) to assess the food intake of patients (e.g., to combat obesity). The food recognition is a challenging task since the food is intrinsically deformable and presents high variability in appearance. Image representation plays a fundamental role. To properly study the peculiarities of the image representation in the food application context, a benchmark dataset is needed. These facts motivate the work presented in this paper. In this work we introduce the UNICT-FD889 dataset. It is the first food image dataset composed by over 800 distinct plates of food which can be used as benchmark to design and compare representation models of food images. We exploit the UNICT-FD889 dataset for Near Duplicate Image Retrieval (NDIR) purposes by comparing three standard state-of-the-art image descriptors: Bag of Textons, PRICoLBP and SIFT. Results confirm that both textures and colors are fundamental properties in food representation. Moreover the experiments point out that the Bag of Textons representation obtained considering the color domain is more accurate than the other two approaches for NDIR.},
author = {Farinella, Giovanni Maria and Allegra, Dario and Stanco, Filippo},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Farinella, Allegra, Stanco - A Benchmark Dataset to Study the Representation of Food Images - European Conference Computer Vision Worksh.pdf:pdf},
journal = {European Conference Computer Vision Workshops},
keywords = {food dataset,food recognition,near duplicate image re-,pricolbp,sift,textons,trieval},
title = {{A Benchmark Dataset to Study the Representation of Food Images}},
year = {2014}
}
@article{Horton1997,
abstract = {We have compared four classifiers on the problem of predicting the cellular localization sites of proteins in yeast and E. coli. A set of sequence derived features, such as regions of high hydrophobicity, were used for each classifier. The methods compared were a structured probabilistic model specifically designed for the localization problem, the k nearest neighbors classifier, the binary decision tree classifier, and the na{\"{\i}}ve Bayes classifier. The result of tests using stratified cross validation shows the k nearest neighbors classifier to perform better than the other methods. In the case of yeast this difference was statistically significant using a cross-validated paired t test. The result is an accuracy of approximately 60{\%} for 10 yeast classes and 86{\%} for 8 E. coli classes. The best previously reported accuracies for these datasets were 55{\%} and 81{\%} respectively.},
author = {Horton, P and Nakai, K},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1997/Horton, Nakai - Better prediction of protein cellular localization sites with the k nearest neighbors classifier. - Proceedings ... Int.pdf:pdf},
isbn = {1553-0833 (Print)},
issn = {1553-0833},
journal = {Proceedings / ... International Conference on Intelligent Systems for Molecular Biology ; ISMB. International Conference on Intelligent Systems for Molecular Biology},
keywords = {classification,classifier,colz,e,k nearest neighbor,protein localization,yeast},
pages = {147--152},
pmid = {9322029},
title = {{Better prediction of protein cellular localization sites with the k nearest neighbors classifier.}},
volume = {5},
year = {1997}
}
@article{Probst2015,
abstract = {Dietary assessment, while traditionally based on pen-and-paper, is rapidly moving towards automatic approaches. This study describes an Australian automatic food record method and its prototype for dietary assessment via the use of a mobile phone and techniques of image processing and pattern recognition. Common visual features including scale invariant feature transformation (SIFT), local binary patterns (LBP), and colour are used for describing food images. The popular bag-of-words (BoW) model is employed for recognizing the images taken by a mobile phone for dietary assessment. Technical details are provided together with discussions on the issues and future work.},
author = {Probst, Yasmine and Nguyen, Duc and Tran, Minh and Li, Wanqing},
doi = {10.3390/nu7085274},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Probst et al. - Dietary Assessment on a Mobile Phone Using Image Processing and Pattern Recognition Techniques Algorithm Design and Syst.pdf:pdf},
issn = {2072-6643},
journal = {Nutrients},
keywords = {"mHealth,food image,food image",food record,image processing,mhealth,pattern recognition},
number = {8},
pages = {6128--6138},
title = {{Dietary Assessment on a Mobile Phone Using Image Processing and Pattern Recognition Techniques: Algorithm Design and System Prototyping}},
url = {http://www.mdpi.com/2072-6643/7/8/5274/},
volume = {7},
year = {2015}
}
@article{Le2011,
abstract = {We consider the problem of building high- level, class-specific feature detectors from only unlabeled data. For example, is it possible to learn a face detector using only unlabeled images? To answer this, we train a 9-layered locally connected sparse autoencoder with pooling and local contrast normalization on a large dataset of images (the model has 1 bil- lion connections, the dataset has 10 million 200x200 pixel images downloaded from the Internet). We train this network using model parallelism and asynchronous SGD on a clus- ter with 1,000 machines (16,000 cores) for three days. Contrary to what appears to be a widely-held intuition, our experimental re- sults reveal that it is possible to train a face detector without having to label images as containing a face or not. Control experiments show that this feature detector is robust not only to translation but also to scaling and out-of-plane rotation. We also find that the same network is sensitive to other high-level concepts such as cat faces and human bod- ies. Starting with these learned features, we trained our network to obtain 15.8{\%} accu- racy in recognizing 20,000 object categories from ImageNet, a leap of 70{\%} relative im- provement over the previous state-of-the-art.},
archivePrefix = {arXiv},
arxivId = {1112.6209},
author = {Le, Quoc V and Ranzato, Marc'Aurelio and Monga, Rajat and Devin, Matthieu and Chen, Kai and Corrado, Greg S and Dean, Jeff and Ng, Andrew Y},
doi = {10.1109/MSP.2011.940881},
eprint = {1112.6209},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2011/Le et al. - Building high-level features using large scale unsupervised learning - International Conference in Machine Learning.pdf:pdf},
isbn = {978-1-4799-0356-6},
issn = {10535888},
journal = {International Conference in Machine Learning},
keywords = {deep learning,unsupervised learning},
pages = {38115},
title = {{Building high-level features using large scale unsupervised learning}},
url = {http://arxiv.org/abs/1112.6209},
year = {2011}
}
@incollection{Theodoridis2009q,
abstract = {This chapter explores the design of linear classifiers, regardless of the underlying distributions describing the training data. The major advantage of linear classifiers is their simplicity and computational attractiveness. The chapter starts with the assumption that all feature vectors from the available classes can be classified correctly using a linear classifier. Techniques are then developed for the computation of the corresponding linear functions. The probability estimation property of the mean square solution, as well as the bias variance dilemma, is briefly mentioned. The basic philosophy underlying the support vector machines is explained. Emphasis is put on the linear separability issue, the perceptron algorithm, and the mean square and least squares solutions. The geometric interpretation offers a better understanding of the SVM theory. The multiclass case for SVM is also presented. Topics of least squares methods, mean square estimation, and logistic discrimination are also explained in the chapter. The perceptron algorithm is explained along with its geometric interpretation, and in the simple two-class case, it is shown that the perceptron algorithm computes the weights of the linear function g(x), provided that the classes are linearly separable.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50005-0},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Chapter 3 Linear Classifiers - Pattern Recognition.pdf:pdf},
isbn = {9781597492720},
pages = {91--150},
publisher = {Elsevier},
title = {{Chapter 3 Linear Classifiers}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500050},
year = {2009}
}
@article{JanErikSolem2012,
abstract = {If you want a basic understanding of computer vision's underlying theory and algorithms, this hands-on introduction is the ideal place to start. You'll learn techniques for object recognition, {\{}3D{\}} reconstruction, stereo imaging, augmented ...},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Jan Erik Solem}},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/felix/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Jan Erik Solem{\_}Programming Computer Vision with Python{\_}Programming Computer Vision with Python.pdf:pdf},
isbn = {1-4493-1653-0},
issn = {1098-6596},
journal = {Programming Computer Vision with Python},
pages = {264},
pmid = {25246403},
title = {{Programming Computer Vision with Python}},
year = {2012}
}
@article{Nguyen2014,
abstract = {This paper proposes food image classification methods exploiting both local appearance and global structural information of food objects. The contribution of the paper is threefold. First, non-redundant local binary pattern (NRLBP) is used to describe the local appearance information of food objects. Second, the structural information of food objects is represented by the spatial relationship between interest points and encoded using a shape context descriptor formed from those interest points. Third, we propose two methods of integrating appearance and structural information for the description and classification of food images. We evaluated the proposed methods on two datasets. Experimental results verified that the combination of local appearance and structural features can improve classification performance.},
author = {Nguyen, Duc Thanh and Zong, Zhimin and Ogunbona, Philip O. and Probst, Yasmine and Li, Wanqing},
doi = {10.1016/j.neucom.2014.03.017},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Nguyen et al. - Food image classification using local appearance and global structural information - Neurocomputing.pdf:pdf},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Food image classification,Local binary pattern,Non-redundant local binary pattern,Shape context},
month = {sep},
pages = {242--251},
title = {{Food image classification using local appearance and global structural information}},
url = {http://www.sciencedirect.com/science/article/pii/S0925231214004317},
volume = {140},
year = {2014}
}
@article{Zong2010,
abstract = {This paper proposes a food image classification method using local textural patterns and their global structure to describe the food image. In this paper, a visual codebook of local textural patterns is created by employing Scale Invariant Feature Transformation (SIFT) interest point detector with the Local Binary Pattern (LBP) feature. In addition to describing the food image using local texture, the global structure of the food object is represented as the spatial distribution of the local textural structures and encoded using shape context. We evaluated the proposed method on the Pittsburgh Fast-Food Image (PFI) dataset. Experimental results showed that the proposed method could obtain better performance than the baseline experiment on the PFI dataset.},
author = {Zong, Zhimin and Nguyen, Duc Thanh and Ogunbona, Philip and Li, Wanqing},
doi = {10.1109/ISM.2010.37},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Zong et al. - On the combination of local texture and global structure for food classification - Proceedings - 2010 IEEE International S.pdf:pdf},
isbn = {9780769542171},
journal = {Proceedings - 2010 IEEE International Symposium on Multimedia, ISM 2010},
keywords = {Bhattacharyya distance,Codeword filtering,Food classification,Local binary pattern,PFID,Shape context},
mendeley-tags = {Bhattacharyya distance,Codeword filtering,PFID},
pages = {204--211},
title = {{On the combination of local texture and global structure for food classification}},
year = {2010}
}
@article{Vedaldi2009,
abstract = {Our objective is to obtain a state-of-the art object category detector by employing a state-of-the-art image classifier to search for the object in all possible image sub-windows. We use multiple kernel learning of Varma and Ray (ICCV 2007) to learn an optimal combination of exponential {\&}amp;{\#}x03C7;<sup>2</sup> kernels, each of which captures a different feature channel. Our features include the distribution of edges, dense and sparse visual words, and feature descriptors at different levels of spatial organization. Such a powerful classifier cannot be tested on all image sub-windows in a reasonable amount of time. Thus we propose a novel three-stage classifier, which combines linear, quasi-linear, and non-linear kernel SVMs. We show that increasing the non-linearity of the kernels increases their discriminative power, at the cost of an increased computational complexity. Our contributions include (i) showing that a linear classifier can be evaluated with a complexity proportional to the number of sub-windows (independent of the sub-window area and descriptor dimension); (ii) a comparison of three efficient methods of proposing candidate regions (including the jumping window classifier of Chum and Zisserman (CVPR 2007) based on proposing windows from scale invariant features); and (Hi) introducing overlap-recall curves as a mean to compare and optimize the performance of the intermediate pipeline stages. The method is evaluated on the PASCAL Visual Object Detection Challenge, and exceeds the performances of previously published methods for most of the classes.},
author = {Vedaldi, Andrea and Gulshan, Varun and Varma, Manik and Zisserman, Andrew},
doi = {10.1109/ICCV.2009.5459183},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Vedaldi et al. - Multiple Kernels for object detection - Proceedings of the IEEE International Conference on Computer Vision.pdf:pdf},
isbn = {9781424444205},
issn = {1550-5499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {606--613},
title = {{Multiple Kernels for object detection}},
year = {2009}
}
@misc{Inc.,
author = {Foo.log inc.},
title = {{Introduction to FoodLog}},
url = {http://www.foodlog.jp/introduction/log},
urldate = {2016-04-04},
year = {2013}
}
@phdthesis{Sheikh2013,
abstract = {The goal of this project is to design a prototype of a smartphone calorie-counting application that uses image recognition to identify food/food products. The application allows a user to take a picture of food using the smartphone's camera; it then attempts to identify the food using Content Based Image Recognition (CBIR) and subsequently retrieve its calories from an online web-service. The user can share the photos online on social networks such as Facebook. The premise is that by allowing the user to take and share photos while recording calories in the background, calorie counting can be made fun, interactive and painless.},
author = {Sheikh, Waqqas and Sheikh, Talal},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Sheikh, Sheikh - Prototype of an Image Recognition Based Calorie Recording Application - Unknown.pdf:pdf},
school = {Heriot Watt University},
title = {{Prototype of an Image Recognition Based Calorie Recording Application}},
year = {2013}
}
@article{Ojala1994,
abstract = {This paper evaluates the performance both of some texture measures which have been successfully used in various applications and of some new promising approaches. For classification a method based on Kullback discrimination of sample and prototype distributions is used. The classification results for single features with one-dimensional feature value distributions and for pairs of complementary features with two-dimensional distributions are presented},
author = {Ojala, T. and Pietikainen, M. and Harwood, D.},
doi = {10.1109/ICPR.1994.576366},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1994/Ojala, Pietikainen, Harwood - Performance evaluation of texture measures with classification based on Kullback discrimination of distrib.pdf:pdf},
isbn = {0-8186-6265-4},
issn = {00313203},
journal = {Proceedings of the 12th IAPR International Conference on Pattern Recognition (ICPR)},
keywords = {Analysis of variance,Autocorrelation,Automation,Distributed computing,Electric variables measurement,Histograms,Image texture analysis,Kullback discrimination,Performance evaluation,Prototypes,Rotation measurement,classification,complementary features,image texture,one-dimensional feature value distributions,performance evaluation,texture measures},
pages = {582--585},
title = {{Performance evaluation of texture measures with classification based on Kullback discrimination of distributions}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=576366},
volume = {1},
year = {1994}
}
@inproceedings{Herranz2015,
abstract = {A large amount of food photos are taken in restaurants for diverse reasons. This dish recognition problem is very challenging, due to different cuisines, cooking styles and the intrinsic difficulty of modeling food from its visual appearance. Contextual knowledge is crucial to improve recognition in such scenario. In particular, geocontext has been widely exploited for outdoor landmark recognition. Similarly, we exploit knowledge about menus and geolocation of restaurants and test images. We first adapt a framework based on discarding unlikely categories located far from the test image. Then we reformulate the problem using a probabilistic model connecting dishes, restaurants and geolocations. We apply that model in three different tasks: dish recognition, restaurant recognition and geolocation refinement. Experiments on a dataset including 187 restaurants and 701 dishes show that combining multiple evidences (visual, geolocation, and external knowledge) can boost the performance in all tasks.},
author = {Herranz, Luis and {Key Lab. of Intell. Inf. Process Beijing China} and Ruihan, Xu and Jiang, Shuqiang},
booktitle = {2015 IEEE International Conference on Multimedia and Expo (ICME)},
doi = {10.1109/ICME.2015.7177464},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Herranz et al. - A probabilistic model for food image recognition in restaurants - 2015 IEEE International Conference on Multimedia and.pdf:pdf},
isbn = {978-1-4799-7082-7},
keywords = {Visualization,catering industry,contextual knowledge,dish recognition,food image recognition,food photos,food recognition,geocontext,geolocation,geolocation refinement,mobile,mobile computing,object recognition,outdoor landmark recognition,probabilistic model,restaurant geolocation,restaurant menu,restaurant recognition,restaurants,statistical analysis,visual appearance},
month = {jun},
pages = {1--6},
publisher = {IEEE},
shorttitle = {Multimedia and Expo (ICME), 2015 IEEE Internationa},
title = {{A probabilistic model for food image recognition in restaurants}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7177464},
year = {2015}
}
@article{Lazebnik2003,
abstract = { This paper introduces a texture representation suitable for recognizing images of textured surfaces under a wide range of transformations, including viewpoint changes and nonrigid deformations. At the feature extraction stage, a sparse set of affine-invariant local patches is extracted from the image. This spatial selection process permits the computation of characteristic scale and neighborhood shape for every texture element. The proposed texture representation is evaluated in retrieval and classification tasks using the entire Brodatz database and a collection of photographs of textured surfaces taken from different viewpoints.},
author = {Lazebnik, S. and Schmid, C. and Ponce, J.},
doi = {10.1109/CVPR.2003.1211486},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2003/Lazebnik, Schmid, Ponce - A sparse texture representation using affine-invariant regions - 2003 IEEE Computer Society Conference on Comp.pdf:pdf},
isbn = {0-7695-1900-8},
issn = {1063-6919},
journal = {2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.},
pmid = {16119265},
title = {{A sparse texture representation using affine-invariant regions}},
volume = {2},
year = {2003}
}
@book{Theodoridis2009u,
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50002-5},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(4).pdf:pdf},
isbn = {9781597492720},
pages = {xv--xvii},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500025},
year = {2009}
}
@phdthesis{Baxter,
abstract = {Food recognition is a difficult problem, because unlike objects like cars, faces, or pedestrians, food is deformable and exhibits high intra-class variation. This paper con- siders the approach of analyzing a food item at the pixel- level by classifying each pixel as a certain ingredient, and then using statistics and spatial relationships between those pixel ingredient labels as features in an SVM classifier. We experimented with multiple variations on past methods, and found that using pixel ingredient labels to identify food greatly increases classification accuracy, but at the expense of higher computational cost.},
author = {Baxter, Jay},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/Unknown/Baxter - Food Recognition using Ingredient-Level Features - Unknown.pdf:pdf},
keywords = {PFID,pairwise statistics of local features},
mendeley-tags = {PFID,pairwise statistics of local features},
school = {Massachusetts Institute of Technology},
title = {{Food Recognition using Ingredient-Level Features}}
}
@article{Kitamura2010,
abstract = {Food images have been receiving increased attention in recent dietary control methods. We present the current status of our web-based system that can be used as a dietary management support system by ordinary Internet users. The system analyzes image archives of the user to identify images of meals. Further image analysis determines the nutritional composition of these meals and stores the data to form a Foodlog. The user can view the data in different formats, and also edit the data to correct any mistakes that occurred during image analysis. This paper presents detailed analysis of the performance of the current system and proposes an improvement of analysis by pre-classification and personalization. As a result, the accuracy of food balance estimation is significantly improved.},
author = {Kitamura, K. and Silva, C. De and Yamasaki, T. and Aizawa, K.},
doi = {10.1109/ICME.2010.5583021},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Kitamura et al. - Image processing based approach to food balance analysis for personal food logging - Multimedia and Expo (ICME), 2010.pdf:pdf},
isbn = {978-1-4244-7491-2},
issn = {1945-7871},
journal = {Multimedia and Expo (ICME), 2010 IEEE International Conference on},
keywords = {Food,Image Processing,life log},
pages = {625--630},
title = {{Image processing based approach to food balance analysis for personal food logging}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5583021},
year = {2010}
}
@article{Abadi2015,
abstract = {TensorFlow [1] is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.},
author = {Abadi, Martin and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Goodfellow, Ian and Harp, Andrew and Irving, Geoffrey and Isard, Michael and Jia, Yangqing and Kaiser, Lukasz and Kudlur, Manjunath and Levenberg, Josh and Man, Dan and Monga, Rajat and Moore, Sherry and Murray, Derek and Shlens, Jon and Steiner, Benoit and Sutskever, Ilya and Tucker, Paul and Vanhoucke, Vincent and Vasudevan, Vijay and Vinyals, Oriol and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Abadi et al. - TensorFlow Large-Scale Machine Learning on Heterogeneous Distributed Systems - None.pdf:pdf},
journal = {None},
pages = {19},
title = {{TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems}},
url = {http://download.tensorflow.org/paper/whitepaper2015.pdf},
year = {2015}
}
@article{Pham2013,
abstract = {We describe FoodBoard, an instrumented chopping board that uses optical fibers and embedded camera imaging to identify unpackaged ingredients during food preparation on its surface. By embedding the sensing directly, and robust- ly, in the surface of a chopping board we also demonstrate how surface contact optical sensing can be used to realize the portability and privacy required of technology used in a setting such as a domestic kitchen. FoodBoard was subject- ed to a close to real-world evaluation in which 12 users prepared actual meals. FoodBoard compared favourably with existing unpackaged food recognition systems, classi- fying a larger number of distinct food ingredients (12 incl. meat, fruit, vegetables) with an average accuracy of 82.8{\%}.},
author = {Pham, Cuong and Jackson, Daniel and Sch{\"{o}}ning, Johannes and Bartindale, Tom and Plotz, Thomas and Olivier, Patrick},
doi = {10.1145/2493432.2493522},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Pham et al. - FoodBoard surface contact imaging for food recognition - Proceedings of the {\ldots}.pdf:pdf},
isbn = {9781450317702},
journal = {Proceedings of the {\ldots}},
keywords = {Food Recognition,H.1.2 User/Machine Systems I.5 Pattern Recognition,Sensing Surfaces,UbiComp},
mendeley-tags = {H.1.2 User/Machine Systems I.5 Pattern Recognition},
pages = {749--752},
title = {{FoodBoard: surface contact imaging for food recognition}},
url = {http://dl.acm.org/citation.cfm?id=2493522},
year = {2013}
}
@misc{Krem,
abstract = {Ein Start-up aus Israel hat ein Ger{\"{a}}t gebaut, das an den Tricorder aus "Star Trek" erinnert. Es soll feste oder fl{\"{u}}ssige Stoffe in Sekundenschnelle analysieren - und das klappt verbl{\"{u}}ffend gut.},
author = {Kremp, Matthias},
keywords = {Mobile World Congress,Sprectral analyse,Tricorder},
mendeley-tags = {Mobile World Congress,Sprectral analyse,Tricorder},
title = {{Mobile World Congress 2016: Ist das wirklich ein Tricorder? - SPIEGEL ONLINE}},
url = {http://www.spiegel.de/netzwelt/gadgets/mobile-world-congress-2016-ist-das-wirklich-ein-tricorder-a-1078790.html},
urldate = {2016-02-23},
year = {2016}
}
@article{bradski2000opencv,
author = {Bradski, Gary and Others},
journal = {Doctor Dobbs Journal},
number = {11},
pages = {120--126},
publisher = {M AND T PUBLISHING INC},
title = {{The opencv library}},
volume = {25},
year = {2000}
}
@article{Savakar2012,
abstract = {This paper presents an recognition and classification of similar looking food grain images using artificial neural networks. Schemes for visual classification usually proceed in two stages. First, features are extracted which represents the image and Second, a classifier is applied to the extracted features to reach a decision regarding the represented type of images. We have considered four pairs of eight different types of similar looking commonly available Indian food grain images namely Jira, Badesoup, Mongdaal Woduddal. Ragi, Mustard, Soya, and Alasandi. The algorithms are developed to extract 18 color and 27 texture features. A Back Propagation Neural Network (BPNN) is used to classify and recognize the Food grain image samples using three different types of feature sets, viz, color, texture, combination of both color and texture features. The study reveals that the combination of color and texture features are out performed the individual color and texture features in recognition and classification of different similar looking food grain images samples.},
author = {Savakar, Dayanand},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Savakar - Recognition and Classification of Similar Looking Food Grain Images using Artificial Neural Networks - Journal of Applied Comp.pdf:pdf},
journal = {Journal of Applied Computer Science {\&} Mathematics, no. 13 (6) /2012, Suceava},
keywords = {Feature extraction,Similar looking food grain images,artificial neural networks},
title = {{Recognition and Classification of Similar Looking Food Grain Images using Artificial Neural Networks}},
url = {http://jacs.usv.ro/getpdf.php?paperid=13{\_}9},
volume = {13},
year = {2012}
}
@article{Lazebnik2006,
abstract = { This paper presents a method for recognizing scene categories based on approximate global geometric correspondence. This technique works by partitioning the image into increasingly fine sub-regions and computing histograms of local features found inside each sub-region. The resulting "spatial pyramid" is a simple and computationally efficient extension of an orderless bag-of-features image representation, and it shows significantly improved performance on challenging scene categorization tasks. Specifically, our proposed method exceeds the state of the art on the Caltech-101 database and achieves high accuracy on a large database of fifteen natural scene categories. The spatial pyramid framework also offers insights into the success of several recently proposed image descriptions, including Torralba{\&}amp;{\#}146;s "gist" and Lowe{\&}amp;{\#}146;s SIFT descriptors.},
author = {Lazebnik, Svetlana and Schmid, Cordelia and Ponce, Jean},
doi = {10.1109/CVPR.2006.68},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2006/Lazebnik, Schmid, Ponce - Beyond bags of features Spatial pyramid matching for recognizing natural scene categories - Proceedings of the.pdf:pdf},
isbn = {0769525970},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2169--2178},
title = {{Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories}},
volume = {2},
year = {2006}
}
@article{Schmidt1999,
author = {Schmidt, Douglas C.},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1999/Schmidt - Wrapper facade a structural pattern for encapsulated functions within classes - C Report.pdf:pdf},
journal = {C++ Report},
pages = {1--10},
title = {{Wrapper facade: a structural pattern for encapsulated functions within classes}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.5282},
year = {1999}
}
@article{Ojala1999,
abstract = {This paper presents an unsupervised texture segmentation method, which uses distributions of local binary patterns and pattern contrasts for measuring the similarity of adjacent image regions during the segmentation process. Nonparametric log-likelihood test, the G statistic, is engaged as a pseudo-metric for comparing feature distributions. A region-based algorithm is developed for coarse image segmentation and a pixelwise classification scheme for improving localization of region boundaries. The performance of the method is evaluated with various types of test images.},
author = {Ojala, Timo and Pietik{\"{a}}inen, Matti},
doi = {10.1016/S0031-3203(98)00038-7},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1999/Ojala, Pietik{\"{a}}inen - Unsupervised texture segmentation using feature distributions - Pattern Recognition.pdf:pdf},
isbn = {0031-3203},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {contrast,feature distribution,g statistic,local binary pattern,spatial operator,texture segmentation},
number = {3},
pages = {477--486},
title = {{Unsupervised texture segmentation using feature distributions}},
volume = {32},
year = {1999}
}
@article{Lee2009,
abstract = {There has been much interest in unsupervised learning of hierarchical generative models such as deep belief networks. Scaling such models to full-sized, high-dimensional images remains a difficult problem. To address this problem, we present the convolutional deep belief network, a hierarchical generative model which scales to realistic image sizes. This model is translation-invariant and supports efficient bottom-up and top-down probabilistic inference. Key to our approach is probabilistic max-pooling, a novel technique which shrinks the representations of higher layers in a probabilistically sound way. Our experiments show that the algorithm learns useful high-level visual features, such as object parts, from unlabeled images of objects and natural scenes. We demonstrate excellent performance on several visual recognition tasks and show that our model can perform hierarchical (bottom-up and top-down) inference over full-sized images.},
author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y},
doi = {10.1145/1553374.1553453},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Lee et al. - Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations - Proceedings of the.pdf:pdf},
isbn = {9781605585161},
issn = {02643294},
journal = {Proceedings of the 26th Annual International Conference on Machine Learning ICML 09},
pages = {1--8},
pmid = {20957573},
title = {{Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations}},
url = {http://portal.acm.org/citation.cfm?doid=1553374.1553453},
volume = {2008},
year = {2009}
}
@phdthesis{Zhang,
abstract = {Ingredients are the core components that make a dish what it is, besides the preparation process. Using the idea of attribute-based classification, we seek to classify plates of food to the correct cuisine by the country, using the in- gredients as attributes for a plate of food. Because of the important role that ingredients have in any plate of food, this method can be generalized to any type of dishes with any type of ingredients, and can learn new dishes not seen in the training, as long as the ingredients can be speci- fied to fit an attribute descriptor. Our dataset came from online sources and includes three cuisines, each with two dishes represented by 76 images. Even though our dataset is limited, reasonable results and a mean accuracy of 82.9{\%} show that the method could be generalized to more cate- gories.},
author = {Zhang, Mabel Mengzi},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/Unknown/Zhang - Identifying the Cuisine of a Plate of Food - Unknown.pdf:pdf},
school = {University of California San Diego},
title = {{Identifying the Cuisine of a Plate of Food}}
}
@article{Rosten,
abstract = {This paper addresses the problem of real-time 3D model-based tracking by combining point-based and edge-based tracking systems. We present a careful analysis of the prop-erties of these two sensor systems and show that this leads to some non-trivial design choices that collectively yield extremely high performance. In particular, we present a method for integrating the two systems and robustly com-bining the pose estimates they produce. Further we show how on-line learning can be used to improve the perfor-mance of feature tracking. Finally, to aid real-time perfor-mance, we introduce the FAST feature detector which can perform full-frame feature detection at 400Hz. The combi-nation of these techniques results in a system which is capa-ble of tracking average prediction errors of 200 pixels. This level of robustness allows us to track very rapid motions, such as 50 • camera shake at 6Hz.},
author = {Rosten, Edward and Drummond, Tom},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/Unknown/Rosten, Drummond - Fusing Points and Lines for High Performance Tracking - Unknown.pdf:pdf},
title = {{Fusing Points and Lines for High Performance Tracking}}
}
@article{Kajiwara2015,
abstract = {This paper presents a system for assisting nutrition management for solitary elderly persons. Since dealing with diseases is one of the important issues for solitary elderly, their health control in daily life has been in focus in recent years. As preprocessing to develop a nutrition management system for solitary elderly, systems for discriminating the category of a food image have been proposed. However, classification of food images is still a challenging task due to the variety of their shape and color. In order to improve the performance on the classification, we propose three regions of interests extracted by HSV-AKAZE. The three regions are used to extract various local features such as AKAZE, HSV-AKAZE, and color information, enhances the classification performance. Evaluation experiments for 2000 food images in 50 categories have shown that the classification accuracy has increased by 8{\%} compared with the existing system.},
author = {Kajiwara, Yusuke and Nakamura, Munehiro and Kimura, Haruhiko},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Kajiwara, Nakamura, Kimura - Classification of Single-Food Images by Combining Local HSV-AKAZE Features and Global Features - Internatio.pdf:pdf},
journal = {International Research Journal of Computer Science (IRJCS)},
keywords = {hsv-akaze,m achine learning,roi,single food image,solitary elderly p ersons},
number = {1},
pages = {12--17},
title = {{Classification of Single-Food Images by Combining Local HSV-AKAZE Features and Global Features}},
volume = {2},
year = {2015}
}
@article{Blechert2014,
abstract = {Our current environment is characterized by the omnipresence of food cues. The sight and smell of real foods, but also graphically depictions of appetizing foods, can guide our eating behavior, for example, by eliciting food craving and influencing food choice. The relevance of visual food cues on human information processing has been demonstrated by a growing body of studies employing food images across the disciplines of psychology, medicine, and neuroscience. However, currently used food image sets vary considerably across laboratories and image characteristics (contrast, brightness, etc.) and food composition (calories, macronutrients, etc.) are often unspecified. These factors might have contributed to some of the inconsistencies of this research. To remedy this, we developed food-pics, a picture database comprising 568 food images and 315 non-food images along with detailed meta-data. A total of N = 1988 individuals with large variance in age and weight from German speaking countries and North America provided normative ratings of valence, arousal, palatability, desire to eat, recognizability and visual complexity. Furthermore, data on macronutrients (g), energy density (kcal), and physical image characteristics (color composition, contrast, brightness, size, complexity) are provided. The food-pics image database is freely available under the creative commons license with the hope that the set will facilitate standardization and comparability across studies and advance experimental research on the determinants of eating behavior.},
author = {Blechert, Jens and Meule, Adrian and Busch, Niko A. and Ohla, Kathrin},
doi = {10.3389/fpsyg.2014.00617},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Blechert et al. - Food-pics An image database for experimental research on eating and appetite - Frontiers in Psychology.pdf:pdf},
isbn = {1664-1078 (Electronic)},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {ERP,Eating behavior,FMRI,Food pictures,Food-cues,Image properties,Obesity,Standardized food images},
number = {JUN},
pages = {1--10},
pmid = {25009514},
title = {{Food-pics: An image database for experimental research on eating and appetite}},
volume = {5},
year = {2014}
}
@misc{Tamrakar2013,
abstract = {A computer-implemented method for estimating a volume of at least one food item on a food plate is disclosed. A first and second plurality of images are received from different positions above a food plate, wherein angular spacing between the positions of the first plurality of images is greater than angular spacing between the positions of the second plurality of images. A first set of poses of each of the first plurality of images is estimated. A second set of poses of each of the second plurality of images is estimated based on at least the first set of poses. A pair of images taken from each of the first and second plurality of images is rectified based on at least the first and second set of poses. A 3D point cloud is reconstructed based on at least the rectified pair of images. At least one surface of the at least one food item above the food plate is estimated based on at least the reconstructed 3D point cloud. The volume of the at least one food item is estimated based on the at least one surface.},
annote = {- Erkennung des Volumens anhand von Stereo Bildern, die mittels Video erkannt werden.

- Ansonsten alles Standard-Kost (Feature Extraction SVMs)},
author = {Tamrakar, Amir and Sawhney, Harpreet Singh and {Yu, Qian, Divakaran}, Ajay},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Tamrakar, Sawhney, Yu, Qian, Divakaran - Method for computing food volume in a method for analyzing food - Unknown.pdf:pdf},
keywords = {SFIT,SRI,Stereo Images,Volume Estimation,k-Nearest-Neighbors,k-means},
mendeley-tags = {SFIT,SRI,Stereo Images,Volume Estimation,k-Nearest-Neighbors,k-means},
month = {jan},
title = {{Method for computing food volume in a method for analyzing food}},
url = {https://www.google.com.ar/patents/US8345930},
year = {2013}
}
@article{Ponrani2014,
abstract = {Now a day’s obesity is a major problem in human life. So the people are very eager to measuring their weight, healthy eating and also avoiding obesity, so they were need a system to measure the calorie and nutrition from the daily in taking food. A new System is proposed to measure the calorie and nutrition from the food image and it helps patients and dieticians for managing their daily in taking food. In this generation the usage of Personal mobile technology such as smart phones or tablets usage has been increased and also the users can carry with them periodically all the time, so by using a built-in camera of mobile the snapshot of food is taken to measure the consumption of calorie and nutrient components. The results have acceptable accuracy in calorie measurement technique can be done by using MATLAB.},
author = {Ponrani, D Seles and Suveka, S Nirmal and Brabha, S Kiran},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Ponrani, Suveka, Brabha - Performance Analysis of SVM to Measure Calorie and Nutrition from Food Images - International Journal of Advan.pdf:pdf},
journal = {International Journal of Advanced Research Trends in Engineering and Technology},
keywords = {Calorie and Nutrition measurement,obesity management},
number = {3},
pages = {93--98},
title = {{Performance Analysis of SVM to Measure Calorie and Nutrition from Food Images}},
volume = {1},
year = {2014}
}
@article{Weiss2010,
author = {Weiss, Rick and Stumbo, Phyllis J and Divakaran, Ajay},
doi = {10.1016/j.jada.2009.10.011},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Weiss, Stumbo, Divakaran - Automatic food documentation and volume computation using digital imaging and electronic transmission. - Jour.pdf:pdf},
issn = {1878-3570},
journal = {Journal of the American Dietetic Association},
keywords = {Artificial Intelligence,Cell Phones,Data Collection,Data Collection: instrumentation,Data Collection: methods,Diet Surveys,Energy Intake,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Image Processing, Computer-Assisted: standards,Pattern Recognition, Automated,Reproducibility of Results,Sensitivity and Specificity,United States},
month = {jan},
number = {1},
pages = {42--4},
pmid = {20102824},
title = {{Automatic food documentation and volume computation using digital imaging and electronic transmission.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2813222{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {110},
year = {2010}
}
@article{VandeSande2010,
abstract = {Image category recognition is important to access visual information on the level of objects and scene types. So far, intensity-based descriptors have been widely used for feature extraction at salient points. To increase illumination invariance and discriminative power, color descriptors have been proposed. Because many different descriptors exist, a structured overview is required of color invariant descriptors in the context of image category recognition. Therefore, this paper studies the invariance properties and the distinctiveness of color descriptors (software to compute the color descriptors from this paper is available from http://www.colordescriptors.com) in a structured way. The analytical invariance properties of color descriptors are explored, using a taxonomy based on invariance properties with respect to photometric transformations, and tested experimentally using a data set with known illumination conditions. In addition, the distinctiveness of color descriptors is assessed experimentally using two benchmarks, one from the image domain and one from the video domain. From the theoretical and experimental results, it can be derived that invariance to light intensity changes and light color changes affects category recognition. The results further reveal that, for light intensity shifts, the usefulness of invariance is category-specific. Overall, when choosing a single descriptor and no prior knowledge about the data set and object and scene categories is available, the OpponentSIFT is recommended. Furthermore, a combined set of color descriptors outperforms intensity-based SIFT and improves category recognition by 8 percent on the PASCAL VOC 2007 and by 7 percent on the Mediamill Challenge.},
author = {van de Sande, Koen E A and Gevers, Theo and Snoek, Cees G M},
doi = {10.1109/TPAMI.2009.154},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/van de Sande, Gevers, Snoek - Evaluating color descriptors for object and scene recognition. - IEEE transactions on pattern analysis and.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Automated,Automated: methods,Color,Colorimetry,Colorimetry: methods,Computer-Assisted,Computer-Assisted: methods,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Pattern Recognition,Reproducibility of Results,Sensitivity and Specificity,Three-Dimensional,Three-Dimensional: methods},
language = {English},
month = {sep},
number = {9},
pages = {1582--96},
pmid = {20634554},
publisher = {IEEE},
title = {{Evaluating color descriptors for object and scene recognition.}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5204091},
volume = {32},
year = {2010}
}
@article{Hsu2002,
abstract = {Support vector machines (SVMs) were originally designed for binary$\backslash$nclassification. How to effectively extend it for multiclass classification$\backslash$nis still an ongoing research issue. Several methods have been proposed$\backslash$nwhere typically we construct a multiclass classifier by combining$\backslash$nseveral binary classifiers. Some authors also proposed methods that$\backslash$nconsider all classes at once. As it is computationally more expensive$\backslash$nto solve multiclass problems, comparisons of these methods using$\backslash$nlarge-scale problems have not been seriously conducted. Especially$\backslash$nfor methods solving multiclass SVM in one step, a much larger optimization$\backslash$nproblem is required so up to now experiments are limited to small$\backslash$ndata sets. In this paper we give decomposition implementations for$\backslash$ntwo such "all-together" methods. We then compare their performance$\backslash$nwith three methods based on binary classifications: "one-against-all,"$\backslash$n"one-against-one," and directed acyclic graph SVM (DAGSVM). Our experiments$\backslash$nindicate that the "one-against-one" and DAG methods are more suitable$\backslash$nfor practical use than the other methods. Results also show that$\backslash$nfor large problems methods by considering all data at once in general$\backslash$nneed fewer support vectors},
author = {Hsu, Chih-Wei and Lin, Chih-Jen},
doi = {10.1109/72.991427},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2002/Hsu, Lin - A comparison of methods for multiclass support vector machines - IEEE Transactions on Neural Networks.pdf:pdf},
isbn = {3-540-32026-1},
issn = {1045-9227},
journal = {IEEE Transactions on Neural Networks},
keywords = {DAGSVM,SVMs,binary classifiers,decomposition,direc},
number = {2},
pages = {415--425},
pmid = {18244499},
title = {{A comparison of methods for multiclass support vector machines}},
volume = {13},
year = {2002}
}
@inproceedings{Eigen2015,
author = {Eigen, David and Fergus, Rob},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Eigen, Fergus - Predicting Depth, Surface Normals and Semantic Labels With a Common Multi-Scale Convolutional Architecture - Proceedings.pdf:pdf},
pages = {2650--2658},
title = {{Predicting Depth, Surface Normals and Semantic Labels With a Common Multi-Scale Convolutional Architecture}},
url = {http://www.cv-foundation.org/openaccess/content{\_}iccv{\_}2015/html/Eigen{\_}Predicting{\_}Depth{\_}Surface{\_}ICCV{\_}2015{\_}paper.html},
year = {2015}
}
@book{Theodoridis2009t,
abstract = {This chapter discusses the feature generation stage using data transformations and dimensionality reduction. Feature generation is important in any pattern recognition task. Given a set of measurements, the goal is to discover compact and informative representations of the obtained data. The basic approach followed in this chapter is to transform a given set of measurements to a new set of features. If the transform is suitably chosen, transform domain features can exhibit high information packing properties compared with the original input samples. The chapter reviews Karhunen–Lo{\`{e}}ve transform and the singular value decomposition as dimensionality reduction techniques. The independent component analysis, nonnegative matrix factorization, and nonlinear dimensionality reduction techniques are presented. Then the discrete Fourier transform, discrete cosine transform, discrete sine transform, Hadamard, and Haar transforms are defined. The rest of the chapter focuses on the discrete time wavelet transform. The chapter also shows that the Fourier transform is just one of the tools from a palette of possible transforms.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50008-6},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(20).pdf:pdf},
isbn = {9781597492720},
pages = {323--409},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500086},
year = {2009}
}
@inproceedings{Sutskever2013,
author = {Sutskever, Ilya and Martens, James and Dahl, George and Hinton, Geoffrey},
booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML-13)},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Sutskever et al. - On the importance of initialization and momentum in deep learning - Proceedings of the 30th International Conference.pdf:pdf},
pages = {1139--1147},
title = {{On the importance of initialization and momentum in deep learning}},
url = {http://machinelearning.wustl.edu/mlpapers/papers/icml2013{\_}sutskever13},
year = {2013}
}
@incollection{Christodoulidis2015,
abstract = {Diet management is a key factor for the prevention and treatment of diet-related chronic diseases. Computer vision systems aim to provide automated food intake assessment using meal images. We propose a method for the recognition of already segmented food items in meal images. The method uses a 6-layer deep convolutional neural network to classify food image patches. For each food item, overlapping patches are extracted and classified and the class with the majority of votes is assigned to it. Experiments on a manually annotated dataset with 573 food items justified the choice of the involved components and proved the effectiveness of the proposed system yielding an overall accuracy of 84.9{\%}.},
annote = {Sehr viele Details zur Konfiguration des NN},
author = {Christodoulidis, Stergios and Anthimopoulos, Marios},
booktitle = {New Trends in Image Analysis and Processing -- ICIAP 2015 Workshops},
doi = {10.1007/978-3-319-23222-5},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Christodoulidis, Anthimopoulos - Food Recognition for Dietary Assessment Using Deep Convolutional Neural Networks - New Trends in Image.pdf:pdf;:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Christodoulidis, Anthimopoulos - Food Recognition for Dietary Assessment Using Deep Convolutional Neural Networks - New Trends in Ima(2).pdf:pdf},
isbn = {978-3-319-23221-8},
keywords = {agement,convolutional neural networks,dietary man-,food recognition,machine learning},
pages = {458--465},
title = {{Food Recognition for Dietary Assessment Using Deep Convolutional Neural Networks}},
url = {http://link.springer.com/10.1007/978-3-319-23222-5},
volume = {9281},
year = {2015}
}
@book{Bishop2006a,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M},
booktitle = {Pattern Recognition},
doi = {10.1117/1.2819119},
eprint = {0-387-31073-8},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2006/Bishop - Pattern Recognition and Machine Learning - Pattern Recognition.pdf:pdf},
isbn = {9780387310732},
issn = {10179909},
number = {4},
pages = {738},
pmid = {8943268},
title = {{Pattern Recognition and Machine Learning}},
url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}
@article{Kloft2011,
author = {Kloft, Marius and Brefeld, Ulf and Sonnenburg, S{\"{o}}ren and Zien, Alexander},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2011/Kloft et al. - l p -Norm Multiple Kernel Learning - The Journal of Machine Learning Research.pdf:pdf},
issn = {1532-4435},
journal = {The Journal of Machine Learning Research},
month = {feb},
pages = {953--997},
publisher = {JMLR.org},
title = {{l p -Norm Multiple Kernel Learning}},
url = {http://dl.acm.org/citation.cfm?id=1953048.2021033},
volume = {12},
year = {2011}
}
@article{Bay2008,
abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF’s application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF’s usefulness in a broad range of topics in computer vision.},
annote = {second version of SURF.},
author = {Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and {Van Gool}, Luc},
doi = {10.1016/j.cviu.2007.09.014},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2008/Bay et al. - Speeded-Up Robust Features (SURF) - Computer Vision and Image Understanding.pdf:pdf},
issn = {10773142},
journal = {Computer Vision and Image Understanding},
keywords = {Camera calibration,Feature description,Interest points,Local features,Object recognition},
month = {jun},
number = {3},
pages = {346--359},
title = {{Speeded-Up Robust Features (SURF)}},
url = {http://www.sciencedirect.com/science/article/pii/S1077314207001555},
volume = {110},
year = {2008}
}
@inproceedings{Beijbom2015,
abstract = {Logging food and calorie intake has been shown to facilitate weight management. Unfortunately, current food logging methods are time-consuming and cumbersome, which limits their effectiveness. To address this limitation, we present an automated computer vision system for logging food and calorie intake using images. We focus on the "restaurant" scenario, which is often a challenging aspect of diet management. We introduce a key insight that addresses this problem specifically: restaurant plates are often both nutritionally and visually consistent across many servings. This insight provides a path to robust calorie estimation from a single RGB photograph: using a database of known food items together with restaurant-specific classifiers, calorie estimation can be achieved through identification followed by calorie lookup. As demonstrated on a challenging Menu-Match dataset and an existing third party dataset, our approach outperforms previous computer vision methods and a commercial calorie estimation app. Our Menu-Match dataset of realistic restaurant meals is made publicly available.},
author = {Beijbom, Oscar and Joshi, Neel and Morris, Dan and Saponas, Scott and Khullar, Siddharth},
booktitle = {2015 IEEE Winter Conference on Applications of Computer Vision},
doi = {10.1109/WACV.2015.117},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Beijbom et al. - Menu-Match Restaurant-Specific Food Logging from Images - 2015 IEEE Winter Conference on Applications of Computer Visio.pdf:pdf},
isbn = {978-1-4799-6683-7},
keywords = {Computer vision,Databases,Estimation,Feature extraction,Image color analysis,Menu-Match dataset,Standards,Visualization,automated computer vision system,calorie estimation,calorie intake logging,catering industry,computer vision,diet management,image classification,image colour analysis,restaurant meals,restaurant plates,restaurant-specific classifiers,restaurant-specific food logging,single RGB photograph},
month = {jan},
pages = {844--851},
publisher = {IEEE},
shorttitle = {Applications of Computer Vision (WACV), 2015 IEEE},
title = {{Menu-Match: Restaurant-Specific Food Logging from Images}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7045971},
year = {2015}
}
@misc{Puri2010,
abstract = {A method and system for analyzing at least one food item on a food plate is disclosed. A plurality of images of the food plate is received by an image capturing device. A description of the at least one food item on the food plate is received by a recognition device. The description is at least one of a voice description and a text description. At least one processor extracts a list of food items from the description; classifies and segments the at least one food item from the list using color and texture features derived from the plurality of images; and estimates the volume of the classified and segmented at least one food item. The processor is also configured to estimate the caloric content of the at least one food item.},
annote = {Kombination Stimme und Visual Patterns

- Colors {\&}amp; Textures mit SVM

Vermutlich nicht sehr zuverl{\"{a}}ssig, da nur Erkennung durch Histogramme und Gradienten.},
author = {Puri, Manika and Zhiwei, Zhu and Lubin, Jeffrey and Pschar, Tom and Divakaran, Ajay and Sawheney, Harpeet S.},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Puri et al. - Food recognition using visual analysis and speech recognition - Unknown.pdf:pdf},
keywords = {Volume Estimation},
mendeley-tags = {Volume Estimation},
month = {jul},
title = {{Food recognition using visual analysis and speech recognition}},
url = {http://www.google.com/patents/US20100173269},
year = {2010}
}
@misc{Funayama2012,
abstract = {Methods and apparatus for operating on images are described, in particular methods and apparatus for interest point detection and/or description working under different scales and with different rotations, e. g. for scale-invariant and rotation-invariant interest point detection and/ or description. The present invention can provide improved or alternative apparatus and methods for matching interest points either in the same image or in a different image. The present invention can provide alternative or improved software for implement ing any of the methods of the invention. The present invention can provide alternative or improved data structures created by multiple ?ltering operations to generate a plurality of ?ltered images as well as data structures for storing the ?ltered images themselves, eg as stored in memory or transmitted through a network. The present invention can provide alter native or improved data structures including descriptors of interest points in images, eg as stored in memory or trans mitted through a network as well as data structures associat ing such descriptors with an original copy of the image or an image derived therefrom, eg a thumbnail image.},
author = {Funayama, Ryuji and Yanagihara, Hiromichi and {Van Gool}, Luc and Tuytelaars, Tinne and Bay, Herbert},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Funayama et al. - ROBUST INTEREST POINT DETECTOR AND DESCRIPTOR - Unknown.pdf:pdf},
isbn = {3540631674},
number = {12},
title = {{ROBUST INTEREST POINT DETECTOR AND DESCRIPTOR}},
volume = {2},
year = {2012}
}
@article{Keller1985,
abstract = {Classification of objects is an important area of research and application in a variety of fields. In the presence of full knowledge of the underlying probabilities, Bayes decision theory gives optimal error rates. In those cases where this information is not present, many algorithms make use of distance or similarity among samples as a means of classification. The K-nearest neighbor decision rule has often been used in these pattern recognition problems. One of the difficulties that arises when utilizing this technique is that each of the labeled samples is given equal importance in deciding the class memberships of the pattern to be classified, regardless of their `typicalness'. The theory of fuzzy sets is introduced into the K-nearest neighbor technique to develop a fuzzy version of the algorithm. Three methods of assigning fuzzy memberships to the labeled samples are proposed, and experimental results and comparisons to the crisp version are presented.},
author = {Keller, James M. and Gray, Michael R.},
doi = {10.1109/TSMC.1985.6313426},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1985/Keller, Gray - A Fuzzy K-Nearest Neighbor Algorithm - IEEE Transactions on Systems, Man and Cybernetics.pdf:pdf},
isbn = {0018-9472},
issn = {21682909},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
number = {4},
pages = {580--585},
title = {{A Fuzzy K-Nearest Neighbor Algorithm}},
volume = {SMC-15},
year = {1985}
}
@inproceedings{Pouladzadeh2012,
abstract = {Emerging food classification methods play an important role in nowadays food recognition applications. For this purpose, a new recognition algorithm for food is presented, considering its shape, color, size, and texture characteristics. Using various combinations of these features, a better classification will be achieved. Based on our simulation results, the proposed algorithm recognizes food categories with an approval recognition rate of 92.6{\%}, in average.},
author = {Pouladzadeh, Parisa and Villalobos, Gregorio and Almaghrabi, Rana and Shirmohammadi, Shervin},
booktitle = {2012 IEEE International Conference on Multimedia and Expo Workshops},
doi = {10.1109/ICMEW.2012.92},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Pouladzadeh et al. - A Novel SVM Based Food Recognition Method for Calorie Measurement Applications - 2012 IEEE International Conference.pdf:pdf},
isbn = {978-1-4673-2027-6},
keywords = {Calories measurement,Feature extraction,Food recognition,Image color analysis,Image segmentation,SVM based food recognition,Shape,Support vector machine (SVM),Support vector machines,Thumb,Training,calorie measurement applications,classification method,color,color characteristics,food recognition applications,image colour analysis,image recognition,image texture,shape characteristics,size and texture detection,size characteristics,support vector machines,texture characteristics},
month = {jul},
pages = {495--498},
publisher = {IEEE},
shorttitle = {Multimedia and Expo Workshops (ICMEW), 2012 IEEE I},
title = {{A Novel SVM Based Food Recognition Method for Calorie Measurement Applications}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6266433},
year = {2012}
}
@article{Wang2009,
abstract = {By combining Histograms of Oriented Gradients (HOG) and Local Binary Pattern (LBP) as the feature set, we propose a novel human detection approach capable of handling partial occlusion. Two kinds of detectors, i.e., global detector for whole scanning windows and part detectors for local regions, are learned from the training data using linear SVM. For each ambiguous scanning window, we construct an occlusion likelihood map by using the response of each block of the HOG feature to the global detector. The occlusion likelihood map is then segmented by Mean-shift approach. The segmented portion of the window with a majority of negative response is inferred as an occluded region. If partial occlusion is indicated with high likelihood in a certain scanning window, part detectors are applied on the unoccluded regions to achieve the final classification on the current scanning window. With the help of the augmented HOG-LBP feature and the global-part occlusion handling method, we achieve a detection rate of 91.3{\%} with FPPW= 10<sup>{\&}amp;{\#}x2212;6</sup>, 94.7{\%} with FPPW= 10<sup>{\&}amp;{\#}x2212;5</sup>, and 97.9{\%} with FPPW= 10<sup>{\&}amp;{\#}x2212;4</sup> on the INRIA dataset, which, to our best knowledge, is the best human detection performance on the INRIA dataset. The global-part occlusion handling method is further validated using synthesized occlusion data constructed from the INRIA and Pascal dataset.},
author = {Wang, Xiaoyu and Han, Tony X. and Yan, Shuicheng},
doi = {10.1109/ICCV.2009.5459207},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Wang, Han, Yan - An HOG-LBP human detector with partial occlusion handling - Computer Vision, 2009 IEEE 12th International Conference on.pdf:pdf},
isbn = {978-1-4244-4420-5},
issn = {1550-5499},
journal = {Computer Vision, 2009 IEEE 12th International Conference on},
number = {Iccv},
pages = {32--39},
title = {{An HOG-LBP human detector with partial occlusion handling}},
year = {2009}
}
@inproceedings{Meyers2015,
author = {Meyers, Austin and Johnston, Nick and Rathod, Vivek and Korattikara, Anoop and Gorban, Alex and Silberman, Nathan and Guadarrama, Sergio and Papandreou, George and Huang, Jonathan and Murphy, Kevin P.},
booktitle = {Proceedings of the IEEE International Conference on Computer Vision},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Meyers et al. - Im2Calories Towards an Automated Mobile Vision Food Diary - Proceedings of the IEEE International Conference on Computer.pdf:pdf},
pages = {1233--1241},
title = {{Im2Calories: Towards an Automated Mobile Vision Food Diary}},
url = {http://www.cv-foundation.org/openaccess/content{\_}iccv{\_}2015/html/Meyers{\_}Im2Calories{\_}Towards{\_}an{\_}ICCV{\_}2015{\_}paper.html},
year = {2015}
}
@article{Burges1998,
abstract = {The tutorial starts with an overview of the concepts of VC dimension and structural risk minimization. We then describe linear Support Vector Machines (SVMs) for separable and non-separable data, working through a non-trivial example in detail. We describe a mechanical analogy, and discuss when SVM solutions are unique and when they are global. We describe how support vector training can be practically implemented, and discuss in detail the kernel mapping technique which is used to construct SVM solutions which are nonlinear in the data. We show how Support Vector machines can have very large (even infinite) VC dimension by computing the VC dimension for homogeneous polynomial and Gaussian radial basis function kernels. While very high VC dimension would normally bode ill for generalization performance, and while at present there exists no theory which shows that good generalization performance is guaranteed for SVMs, there are several arguments which support the observed high accuracy of SVMs, which we review. Results of some experiments which were inspired by these arguments are also presented. We give numerous examples and proofs of most of the key theorems. There is new material, and I hope that the reader will find that even old material is cast in a fresh light.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Burges, CJC Christopher J C},
doi = {10.1023/A:1009715923555},
editor = {Fayyad, Usama},
eprint = {1111.6189v1},
institution = {Bell Laboratories, Lucent Technologies},
isbn = {0818672404},
issn = {13845810},
journal = {Data Mining and Knowledge Discovery},
keywords = {pattern recognition,statistical learning theory,support vector machines,vc dimension},
number = {2},
pages = {121--167},
pmid = {5207842081938259593},
publisher = {Springer},
series = {NetGames '06},
title = {{A Tutorial on Support Vector Machines for Pattern Recognition}},
url = {http://www.springerlink.com/index/Q87856173126771Q.pdf$\backslash$nhttp://link.springer.com/article/10.1023/A:1009715923555},
volume = {2},
year = {1998}
}
@article{Ojala2002,
author = {Ojala, T. and Pietikainen, M. and Maenpaa, T.},
doi = {10.1109/TPAMI.2002.1017623},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2002/Ojala, Pietikainen, Maenpaa - Multiresolution gray-scale and rotation invariant texture classification with local binary patterns - IEEE.pdf:pdf},
issn = {0162-8828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Gray-scale,Histograms,Image recognition,Image texture,Multiresolution analysis,Pattern recognition,Prototypes,Quantization,Robustness,Spatial resolution,angular space,computational simplicity,gray-scale variations,image classification,image texture,invariance,local binary patterns,local image texture,multiresolution analysis,multiresolution gray-scale texture classification,nonparametric discrimination,nonparametric statistics,occurrence histogram,prototype distributions,rotation invariant texture classification,sample distributions,spatial resolution,uniform patterns},
language = {English},
month = {jul},
number = {7},
pages = {971--987},
publisher = {IEEE},
title = {{Multiresolution gray-scale and rotation invariant texture classification with local binary patterns}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1017623},
volume = {24},
year = {2002}
}
@book{Theodoridis2009j,
abstract = {This chapter presents basic concepts and definitions related to clustering. The various types of data encountered in clustering applications are reviewed. The chapter explains the basic steps that an expert must follow in order to develop a clustering task. Clustering is one of the most primitive mental activities of humans, used to handle the huge amount of information they receive every day. Humans tend to categorize different entities into clusters. Each cluster is then characterized by the common attributes of the entities it contains. Clustering may be found under different names in different contexts, such as unsupervised learning and learning without a teacher (in pattern recognition), numerical taxonomy (in biology, ecology), typology (in social sciences), and partition (in graph theory). In the chapter, examples are presented to show that the process of assigning objects to clusters may lead to very different results depending on the specific criterion used for clustering. The chapter explains the concepts of proximity measures between two points and the proximity functions between two sets. Proximity measures that are commonly encountered in various applications are also discussed.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50013-X},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(15).pdf:pdf},
isbn = {9781597492720},
pages = {595--625},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B978159749272050013X},
year = {2009}
}
@article{Deng2001,
author = {Deng, Yining and Manjunath, B S},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2001/Deng, Manjunath - Unsupervised Segmentation of Color-TextureRegions in Images and Video - Ieee Transactions on Pattern Analysis and Mach.pdf:pdf},
journal = {Ieee Transactions on Pattern Analysis and Machine Intelligence},
pages = {800--810},
title = {{Unsupervised Segmentation of Color-TextureRegions in Images and Video}},
volume = {23},
year = {2001}
}
@inproceedings{Kitamura2008,
address = {New York, New York, USA},
author = {Kitamura, Keigo and Yamasaki, Toshihiko and Aizawa, Kiyoharu},
booktitle = {Proceeding of the 16th ACM international conference on Multimedia - MM '08},
doi = {10.1145/1459359.1459548},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2008/Kitamura, Yamasaki, Aizawa - Food log by analyzing food images - Proceeding of the 16th ACM international conference on Multimedia - MM.pdf:pdf},
isbn = {9781605583037},
keywords = {food,life-log,multimedia interfaces},
month = {oct},
pages = {999},
publisher = {ACM Press},
title = {{Food log by analyzing food images}},
url = {http://dl.acm.org/citation.cfm?id=1459359.1459548},
year = {2008}
}
@article{Joutou2009,
abstract = {Since health care on foods is drawing people’s attention recently, a system that can record everyday meals easily is being awaited. In this paper, we propose an automatic food image recognition system for recording people’s eating habits. In the proposed system, we use the Multiple Kernel Learning (MKL) method to integrate several kinds of image features such as color, texture and SIFT adaptively. MKL enables to estimate optimal weights to combine image features for each category. In addition, we implemented a prototype system to recognize food images taken by cellular-phone cameras. In the experiment, we have achieved the 61.34{\%} classification rate for 50 kinds of foods. To the best of our knowledge, this is the first report of a food image classification system which can be applied for practical use.},
annote = {sch{\"{o}}ner Vergleich der Feature Extraction Algorithmen -{\&}gt; performen nicht sehr gut.
Erst mit MKL gut},
author = {Joutou, Taichi and Yanai, Keiji and Joutou, Taichi},
doi = {10.1109/ICIP.2009.5413400},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Joutou, Yanai, Joutou - A Food Image Recognition System With Multiple Kernel Learning - IEEE International Conference on Image Processin.pdf:pdf},
isbn = {978-1-4244-5653-6},
issn = {9781424456543},
journal = {IEEE International Conference on Image Processing (ICIP)},
keywords = {BoF,BoW,Color histogram,DoG,Feature Fusion,Gabor Texture Features,Multiple Kernel Learning,SIFT,SVM,food image,generic object recognition,multiple kernel learning},
mendeley-tags = {BoF,BoW,Color histogram,DoG,Feature Fusion,Multiple Kernel Learning,SIFT,SVM},
pages = {285--288},
title = {{A Food Image Recognition System With Multiple Kernel Learning}},
url = {file://filesrv01/mv{\_}mendeley{\_}db{\$}/A Food Image Recognition System with Multiple Kernel Learning{\_}Joutou, Yanai{\_}2009.pdf},
year = {2009}
}
@article{scikit-image,
author = {van der Walt, St{\'{e}}fan and Sch{\"{o}}nberger, Johannes L and Nunez-Iglesias, Juan and Boulogne, Fran{\c{c}}ois and Warner, Joshua D and Yager, Neil and Gouillart, Emmanuelle and Yu, Tony and The scikit-image contributors},
doi = {10.7717/peerj.453},
issn = {2167-8359},
journal = {PeerJ},
keywords = {Education,Image processing,Open source,Python,Reproducible research,Scientific programming,Visualization},
pages = {e453},
title = {{scikit-image: image processing in {\{}P{\}}ython}},
url = {http://dx.doi.org/10.7717/peerj.453},
volume = {2},
year = {2014}
}
@article{Surya2015,
abstract = {Obesity is the major cause of overweight this leads to the type II diabetes, heart disease and cancer. Measuring the food is very important for a successful healthy diet. Measuring calorie and nutrition in daily food is one of the challenge methods. Smartphone plays a vital role in today’s technological world using this technique will enhance the issue in intake of dietary consumption .In this project an food image recognition system for measuring the calorie and nutrition values was developed .the user has to take the picture of the food image this system will classify the image to detect the type of food and portion size and the recognition information will estimate the number of calories in the food. In this system the food area, size and volume will be used to calculate the calorie and nutrition in accurate way.},
annote = {what a bad paper},
author = {Surya, R and Priya, S Saru},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Surya, Priya - Food Image Recognition Using Svm Classifier for Measuring Calorie and Nutrition Values - International Journal of Scienti.pdf:pdf},
journal = {International Journal of Scientific {\&} Engineering Research},
keywords = {Feature extraction.,Food image,Pre-processing,Support vector machine (SVM),and,announcement cost,feature extraction,food image,image recognition smartphone is,in terms of obtainability,interruption,much more capable,other hand,pre-processing,support vector machine,svm},
number = {4},
pages = {324--328},
title = {{Food Image Recognition Using Svm Classifier for Measuring Calorie and Nutrition Values}},
url = {http://www.ijser.org/researchpaper$\backslash$Food-Image-Recognition-Using-Svm-Classifier-for-Measuring-Calorie-and-Nutrition-Values.pdf},
volume = {6},
year = {2015}
}
@article{Morvant2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1404.7796v1},
author = {Morvant, Emilie and Habrard, Amaury and Ayache, St??phane},
doi = {10.1007/978-3-662-44415-3{\_}16},
eprint = {arXiv:1404.7796v1},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Morvant, Habrard, Ayache - Majority vote of diverse classifiers for late fusion - Lecture Notes in Computer Science (including subseries.pdf:pdf},
isbn = {9783662444146},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Classifier fusion,Majority vote,Multimedia analysis,Ranking},
pages = {153--162},
title = {{Majority vote of diverse classifiers for late fusion}},
volume = {8621 LNCS},
year = {2014}
}
@book{Theodoridis2009k,
abstract = {This chapter deals with problems that are not linearly separable and for which the design of a linear classifier, even in an optimal way, does not lead to satisfactory performance. The XOR problem is examined, and the procedure is then applied to more general cases of nonlinearly separable classes. The chapter discusses the capabilities of a multilayer perceptron, with one hidden layer and units of the McCulloch–Pitts type, to divide the input one-dimenesional space into a number of polyhedral regions. Techniques for training neural networks are explored. Pruning is discussed with an emphasis on generalization issues. Emphasis is also given to Cover's theorem and radial basis function (RBF) networks. The nonlinear support vector machines, decision trees, and combining classifiers are briefly discussed. The concept of combining classifiers is also discussed. One section reviews a large class of nonlinear classifiers known as decision trees, which are multistage decision systems in which classes are sequentially rejected until a finally accepted class is reached.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50006-2},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(7).pdf:pdf},
isbn = {9781597492720},
pages = {151--260},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500062},
year = {2009}
}
@article{LeCunJackelB.BoserJ.S.DenkerD.HendersonR.E.HowardW.Hubbard1990,
abstract = {We present an application of back-propagation networks to handwritten digit recognition. Minimal preprocessing of the data was required, but architecture of the network was highly constrained and specifically designed for the task. The input of the network consists of normalized images of isolated digits. The method has 1{\%} error rate and about a 9{\%} reject rate on zipcode digits provided by the U.S. Postal Service.},
archivePrefix = {arXiv},
arxivId = {1004.3732},
author = {{Le Cun Jackel, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard}, L. D. and Cun, Bb Le and Denker, Js and Henderson, D.},
doi = {10.1111/dsu.12130},
eprint = {1004.3732},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1990/Le Cun Jackel, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard et al. - Handwritten Digit Recognition with a Back-Propaga.pdf:pdf},
isbn = {1-55860-100-7},
issn = {1524-4725},
journal = {Advances in Neural Information Processing Systems},
pages = {396--404},
pmid = {23301817},
title = {{Handwritten Digit Recognition with a Back-Propagation Network}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.5076$\backslash$nhttp://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.32.5076{\&}rep=rep1{\&}type=pdf},
year = {1990}
}
@article{Kawano2014,
abstract = {Abstract In this paper, we report the feature obtained from the Deep Convolutional Neural Network boosts food recognition accuracy greatly by integrating it with conventional hand-crafted image features, Fisher Vectors with HoG and Color patches. In the experiments, we have achieved 72.26{\%} as the top-1 accuracy and 92.00{\%} as the top-5 accuracy for the 100-class food dataset, UEC-FOOD100, which outperforms the best classification accuracy of this dataset reported so far, 59.6{\%}, greatly.},
author = {Kawano, Yoshiyuki and Yanai, Keiji},
doi = {10.1145/2638728.2641339},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Kawano, Yanai - Food Image Recognition with Deep Convolutional Features - ACM International Joint Conference on Pervasive and Ubiquit(2).pdf:pdf},
isbn = {9781450330473},
journal = {ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp)},
pages = {589--593},
title = {{Food Image Recognition with Deep Convolutional Features}},
year = {2014}
}
@article{LeCun1998,
abstract = {Multilayer neural networks trained with the back-propagation$\backslash$nalgorithm constitute the best example of a successful gradient based$\backslash$nlearning technique. Given an appropriate network architecture,$\backslash$ngradient-based learning algorithms can be used to synthesize a complex$\backslash$ndecision surface that can classify high-dimensional patterns, such as$\backslash$nhandwritten characters, with minimal preprocessing. This paper reviews$\backslash$nvarious methods applied to handwritten character recognition and$\backslash$ncompares them on a standard handwritten digit recognition task.$\backslash$nConvolutional neural networks, which are specifically designed to deal$\backslash$nwith the variability of 2D shapes, are shown to outperform all other$\backslash$ntechniques. Real-life document recognition systems are composed of$\backslash$nmultiple modules including field extraction, segmentation recognition,$\backslash$nand language modeling. A new learning paradigm, called graph transformer$\backslash$nnetworks (GTN), allows such multimodule systems to be trained globally$\backslash$nusing gradient-based methods so as to minimize an overall performance$\backslash$nmeasure. Two systems for online handwriting recognition are described.$\backslash$nExperiments demonstrate the advantage of global training, and the$\backslash$nflexibility of graph transformer networks. A graph transformer network$\backslash$nfor reading a bank cheque is also described. It uses convolutional$\backslash$nneural network character recognizers combined with global training$\backslash$ntechniques to provide record accuracy on business and personal cheques.$\backslash$nIt is deployed commercially and reads several million cheques per day$\backslash$n},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {LeCun, Yann and Bottou, L{\'{e}}on and Bengio, Yoshua and Haffner, Patrick},
doi = {10.1109/5.726791},
eprint = {1102.0183},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1998/LeCun et al. - Gradient-based learning applied to document recognition - Proceedings of the IEEE.pdf:pdf},
isbn = {0018-9219},
issn = {00189219},
journal = {Proceedings of the IEEE},
keywords = {Convolutional neural networks,Document recognition,Finite state transducers,Gradient-based learning,Graph transformer networks,Machine learning,Neural networks,Optical character recognition (OCR)},
number = {11},
pages = {2278--2323},
pmid = {15823584},
title = {{Gradient-based learning applied to document recognition}},
volume = {86},
year = {1998}
}
@inproceedings{Snoek2005,
address = {New York, New York, USA},
annote = {Kombinieren von mehreren Features um die Rate zu verbessern.},
author = {Snoek, Cees G. M. and Worring, Marcel and Smeulders, Arnold W. M.},
booktitle = {Proceedings of the 13th annual ACM international conference on Multimedia - MULTIMEDIA '05},
doi = {10.1145/1101149.1101236},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2005/Snoek, Worring, Smeulders - Early versus late fusion in semantic video analysis - Proceedings of the 13th annual ACM international confe.pdf:pdf},
isbn = {1595930442},
keywords = {Early Fusion,Feature Fusion,Late Fusion,early fusion,late fusion,multimedia understanding,semantic concept detection},
mendeley-tags = {Early Fusion,Feature Fusion,Late Fusion},
month = {nov},
pages = {399},
publisher = {ACM Press},
title = {{Early versus late fusion in semantic video analysis}},
url = {http://dl.acm.org/citation.cfm?id=1101149.1101236},
year = {2005}
}
@article{Witkin1983,
abstract = {The extrema in a signal and its first few derivatives provide a useful general-purpose qualitative description for many kinds of signals. A fundamental problem in computing such descriptions is scale: a derivative must be taken over some neighborhood, but there is seldom a principled basis for choosing its size. Scale-space filtering is a method that describes signals qualitatively, managing the ambiguity of scale in an organized and natural way. The signal is first expanded by convolution with gaussian masks over a continuum of sizes. This "scale-space" image is then collapsed, using its qualitative structure, into a tree providing a concise but complete qualitative description covering all scales of observation. The description is further refined by applying a stability criterion, to identify events that persist of large changes in scale.},
archivePrefix = {arXiv},
arxivId = {http://dl.acm.org/citation.cfm?id=1623607},
author = {Witkin, Andrew P},
doi = {10.1109/ICASSP.1984.1172729},
eprint = {/dl.acm.org/citation.cfm?id=1623607},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1983/Witkin - Scale-space filtering - International Joint Conference on Artificial Intelligence.pdf:pdf},
isbn = {0865760640},
journal = {International Joint Conference on Artificial Intelligence},
pages = {1019--1022},
primaryClass = {http:},
title = {{Scale-space filtering}},
url = {http://portal.acm.org/citation.cfm?id=1623607},
volume = {2},
year = {1983}
}
@article{Russakovsky2015,
abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide detailed a analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.},
archivePrefix = {arXiv},
arxivId = {1409.0575},
author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
doi = {10.1007/s11263-015-0816-y},
eprint = {1409.0575},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Russakovsky et al. - ImageNet Large Scale Visual Recognition Challenge - International Journal of Computer Vision.pdf:pdf},
isbn = {0920-5691},
issn = {15731405},
journal = {International Journal of Computer Vision},
keywords = {Benchmark,Dataset,Large-scale,Object detection,Object recognition},
number = {3},
pages = {211--252},
publisher = {Springer US},
title = {{ImageNet Large Scale Visual Recognition Challenge}},
url = {http://dx.doi.org/10.1007/s11263-015-0816-y},
volume = {115},
year = {2015}
}
@article{Yang2010,
abstract = {Food recognition is difficult because food items are de-formable objects that exhibit significant variations in appearance. We believe the key to recognizing food is to exploit the spatial relationships between different ingredients (such as meat and bread in a sandwich). We propose a new representation for food items that calculates pairwise statistics between local features computed over a soft pixel-level segmentation of the image into eight ingredient types. We accumulate these statistics in a multi-dimensional histogram, which is then used as a feature vector for a discriminative classifier. Our experiments show that the proposed representation is significantly more accurate at identifying food than existing methods.},
author = {Yang, Shulin and Chen, Mei and Pomerleau, Dean and Sukthankar, Rahul},
doi = {10.1109/CVPR.2010.5539907},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Yang et al. - Food recognition using statistics of pairwise local features - Proceedings of the IEEE Computer Society Conference on Comp.pdf:pdf},
isbn = {9781424469840},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
pages = {2249--2256},
title = {{Food recognition using statistics of pairwise local features}},
year = {2010}
}
@article{Weinberger2005,
author = {Weinberger, Kilian Q and Blitzer, John and Saul, Lawrence K},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2005/Weinberger, Blitzer, Saul - {\{}D{\}}istance {\{}M{\}}etric {\{}L{\}}earning for {\{}L{\}}arge {\{}M{\}}argin {\{}N{\}}earest {\{}N{\}}eighbor {\{}C{\}}lassification - {\{}A{\}}dvances in {\{}N.pdf:pdf}},
journal = {{\{}A{\}}dvances in {\{}N{\}}eural {\{}I{\}}nformation {\{}P{\}}rocessing {\{}S{\}}ystems (NIPS)},
keywords = {metric learning},
pages = {1473--1480},
title = {{{\{}D{\}}istance {\{}M{\}}etric {\{}L{\}}earning for {\{}L{\}}arge {\{}M{\}}argin {\{}N{\}}earest {\{}N{\}}eighbor {\{}C{\}}lassification}},
volume = {18},
year = {2005}
}
@article{Szegedy2014,
abstract = {Abstract We propose a deep convolutional neural network architecture codenamed Incep- tion, which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
archivePrefix = {arXiv},
arxivId = {1409.4842},
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
doi = {10.1109/ICCV.2011.6126456},
eprint = {1409.4842},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Szegedy et al. - Going Deeper with Convolutions - arXiv preprint arXiv1409.4842.pdf:pdf},
isbn = {9781467369640},
issn = {1550-5499},
journal = {arXiv preprint arXiv:1409.4842},
pages = {1--12},
title = {{Going Deeper with Convolutions}},
url = {http://arxiv.org/abs/1409.4842v1},
year = {2014}
}
@inproceedings{Hu2012,
abstract = {Dietary treatment is the basic therapy for diabetes, but how to do the right food intake is the biggest discouraging problem. We present a proposal for mobile phone diabetes food information display which can help determine the food composition and calories automatically from the clinical point of view with the mature communication technology. We analyzed the composite of the device, especially the key technical method, which is digital image recognition, three-dimensional image analysis, standard tables of food composition database and composite meals energy calculation auxiliary knowledge base. The device has technical feasibility and broad application prospects. It’s combination of dietary treatment with smart mobile technology, which can provide great support to solve the problem of food energy assessment and analysis, not only for the single-ingredient food but also the composite meals. The proposal also provides further thinking about how to improve adherence to medical nutrition treatment in diabetes.},
author = {Hu, Jing-sheng and Jiang, Chen},
booktitle = {National Conference on Information Technology and Computer Science},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Hu, Jiang - A Proposal for Automatic Diabetes Food Information Display with Mobile Phone - National Conference on Information Technology.pdf:pdf},
isbn = {9789491216381},
keywords = {-dietary assessment,3D REconstruction,Volume Estimation,also known as,analysis,device,dietary treatment,image,is the base treatment,medical nutrition therapy,over the world,prevalence of diabetes all,smart mobile phone},
mendeley-tags = {3D REconstruction,Volume Estimation},
number = {Citcs},
pages = {43--46},
title = {{A Proposal for Automatic Diabetes Food Information Display with Mobile Phone}},
year = {2012}
}
@article{Felzenszwalb2010,
abstract = {We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL datasets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin- sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI-SVM in terms of latent variables. A latent SVM is semi-convex and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.},
author = {Felzenszwalb, P F and Girshick, R B and McAllester, D and Ramanan, D},
doi = {10.1109/TPAMI.2009.167},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Felzenszwalb et al. - Object Detection with Discriminative Trained Part Based Models - IEEE Transactions on Pattern Analysis and Machine.pdf:pdf},
isbn = {0162-8828 VO - 32},
issn = {1939-3539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Object Detection; Object Localization; Part-based},
number = {9},
pages = {1627--1645},
pmid = {20634557},
title = {{Object Detection with Discriminative Trained Part Based Models}},
volume = {32},
year = {2010}
}
@article{Fei-Fei2005,
abstract = {We propose a novel approach to learn and recognize natural scene categories. Unlike previous work, it does not require experts to annotate the training set. We represent the image of a scene by a collection of local regions, denoted as codewords obtained by unsupervised learning. Each region is represented as part of a "theme". In previous work, such themes were learnt from hand-annotations of experts, while our method learns the theme distributions as well as the codewords distribution over the themes without supervision. We report satisfactory categorization performances on a large set of 13 categories of complex scenes.},
author = {Fei-Fei, Li and Perona, P.},
doi = {10.1109/CVPR.2005.16},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2005/Fei-Fei, Perona - A Bayesian hierarchical model for learning natural scene categories - 2005 IEEE Computer Society Conference on Compute.pdf:pdf},
isbn = {0-7695-2372-2},
issn = {1063-6919},
journal = {2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)},
keywords = {Animals,Bag of Words,Bayesian hierarchical model,Bayesian methods,BoF,BoW,Cities and towns,Dictionaries,Frequency,Histograms,Humans,Layout,Unsupervised learning,Vehicles,belief networks,codeword distribution,image classification,image representation,learning natural scene category,natural scenes,training set,unsupervised learning},
mendeley-tags = {Bag of Words,BoF,BoW},
pages = {524--531},
title = {{A Bayesian hierarchical model for learning natural scene categories}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1467486},
volume = {2},
year = {2005}
}
@article{Viola2001,
abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "integral image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on AdaBoost, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
author = {Viola, P and Jones, M},
doi = {10.1109/CVPR.2001.990517},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2001/Viola, Jones - Rapid object detection using a boosted cascade of simple features - Conference on Computer Vision and Pattern Recognition.pdf:pdf},
isbn = {0-7695-1272-0},
issn = {1063-6919},
journal = {Conference on Computer Vision and Pattern Recognition (CVPR)},
pmid = {7143246},
title = {{Rapid object detection using a boosted cascade of simple features}},
year = {2001}
}
@book{Theodoridis2009i,
abstract = {This chapter discusses the concept of hierarchical clustering algorithms. These algorithms produce a hierarchy of clustering and are usually found in the social sciences and biological taxonomy. They have also been used in many other fields, including modern biology, medicine, and archaeology. Applications of the hierarchical algorithms may also be found in computer science and engineering. Hierarchical clustering algorithms produce a hierarchy of nested clustering. These algorithms involve N steps, as many as the number of data vectors. A hierarchical algorithm can be viewed as a mapping of the data proximity matrix into a cophenetic matrix. The chapter explains in detail two main categories of hierarchical algorithms: the agglomerative and the divisive hierarchical algorithms. While explaining the general agglomerative scheme, the emphasis is on single link and complete link algorithms based on matrix theory. A special type of hierarchical algorithms that are most appropriate for handling large data sets is discussed. The need for such algorithms stems from a number of applications, such as Web mining and bioinformatics.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50015-3},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(12).pdf:pdf},
isbn = {9781597492720},
pages = {653--700},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500153},
year = {2009}
}
@article{Chih-WeiHsuChih-ChungChang2008,
abstract = {The support vector machine (SVM) is a popular classi cation technique. However, beginners who are not familiar with SVM often get unsatisfactory results since they miss some easy but signi cant steps. In this guide, we propose a simple procedure which usually gives reasonable results. developed well-differentiated superficial transitional cell bladder cancer. CONCLUSIONS: Patients with SCI often prefer SPC than other methods offered to them, because of quality-of-life issues. The incidence of significant complications might not be as high as previously reported, and with a commitment to careful follow-up, SPC can be a safe option for carefully selected patients if adequate surveillance can be ensured.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {{Chih-Wei Hsu, Chih-Chung Chang}, and Chih-Jen Lin},
doi = {10.1177/02632760022050997},
eprint = {0-387-31073-8},
isbn = {013805326X},
issn = {1464-410X},
journal = {BJU international},
number = {1},
pages = {1396--400},
pmid = {18190633},
title = {{A Practical Guide to Support Vector Classification}},
url = {http://www.csie.ntu.edu.tw/{~}cjlin/papers/guide/guide.pdf},
volume = {101},
year = {2008}
}
@article{Pedregosa2011,
abstract = {Abstract Scikit - learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high- ... $\backslash$n},
archivePrefix = {arXiv},
arxivId = {arXiv:1201.0490v2},
author = {Pedregosa, Fabian and Varoquaux, G},
doi = {10.1007/s13398-014-0173-7.2},
eprint = {arXiv:1201.0490v2},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2011/Pedregosa, Varoquaux - Scikit-learn Machine learning in Python - {\ldots} of Machine Learning {\ldots}.pdf:pdf},
isbn = {9781783281930},
issn = {15324435},
journal = {{\ldots} of Machine Learning {\ldots}},
pages = {2825--2830},
pmid = {1000044560},
title = {{Scikit-learn: Machine learning in Python}},
url = {http://dl.acm.org/citation.cfm?id=2078195},
volume = {12},
year = {2011}
}
@incollection{Shimoda2015,
abstract = {We propose a CNN-based food image segmentation which requires no pixel-wise annotation. The proposed method consists of food region proposals by selective search and bounding box clustering, back propagation based saliency map estimation with the CNN model fine-tuned with the UEC-FOOD100 dataset, GrabCut guided by the estimated saliency maps and region integration by non-maximum suppression. In the experiments, the proposed method outperformed RCNN regarding food region detection as well as the PASCAL VOC detection task.},
address = {Cham},
author = {Shimoda, Wataru and Yanai, Keiji},
booktitle = {New Trends in Image Analysis and Processing -- ICIAP 2015 Workshops},
doi = {10.1007/978-3-319-23222-5},
editor = {Murino, Vittorio and Puppo, Enrico and Sona, Diego and Cristani, Marco and Sansone, Carlo},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Shimoda, Yanai - CNN-based Food Image Segmentation without Pixel-Wise Annotation - New Trends in Image Analysis and Processing -- ICIAP.pdf:pdf;:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Shimoda, Yanai - CNN-based Food Image Segmentation without Pixel-Wise Annotation - New Trends in Image Analysis and Processing -- ICI(2).pdf:pdf},
isbn = {978-3-319-23221-8},
keywords = {Food segmentation Convolutional neural network Dee},
mendeley-tags = {Food segmentation Convolutional neural network Dee},
pages = {449--457},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{CNN-based Food Image Segmentation without Pixel-Wise Annotation}},
url = {http://link.springer.com/10.1007/978-3-319-23222-5},
volume = {9281},
year = {2015}
}
@book{Theodoridis2009a,
abstract = {This chapter discusses the basic concepts of context-dependent classification. Context-dependent classification can also be emancipated from its Bayesian root. This can be achieved by adopting different transition costs, which are not necessarily related to probability densities. The chapter introduces hidden Markov models (HMM) which are one of the most widely used models describing the underlying class dependence. The Markov chain models are applied to communications and speech recognition. Concepts of continuous observation HMM, HMM with state duration modeling, HMM with duration modeling, best path method, segment modeling, and Markov random fields are explained. The chapter also focuses on training Markov models via neural networks. Feature vectors in this chapter are referred as observations occurring in sequence, one after the other. Two typical application areas of the Viterbi algorithm are presented in the chapter. A simple example is presented to reveal how the equalization problem comes under the umbrella of a Markovian context-dependent classification task. Examples in the chapter show that equalization problem can be defined as a context-dependent classification task. The chapter explains the context-dependent classification in one-dimensional and related two-dimensional generalizations.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50011-6},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(9).pdf:pdf},
isbn = {9781597492720},
pages = {521--565},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500116},
year = {2009}
}
@article{Zepeda2008,
abstract = {This paper examines the use of photographic and written food diaries as interventions to raise awareness of and change dietary habits. Weinstein's precaution adoption theory and Guagnano, Stern and Dietz's Attitude Behaviour Context theory provide the theoretical basis to explain why nutrition knowledge does not result in healthy eating behaviour and why an intervention may be necessary to change attitudes and behaviours. A pilot study using written and photographic food diaries was conducted with 43 participants. Qualitative analysis of participant interviews revealed that photographic food diaries can alter attitudes and behaviours associated with food choices, and they are more likely to do so than written diaries because they serve as an intervention at the point when decisions regarding what to eat are being made.},
author = {Zepeda, Lydia and Deal, David},
doi = {10.1111/j.1470-6431.2008.00725.x},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2008/Zepeda, Deal - Think before you eat photographic food diaries as intervention tools to change dietary decision making and attitudes - In.pdf:pdf},
isbn = {1470-6423},
issn = {14706423},
journal = {International Journal of Consumer Studies},
keywords = {abc theory,dietary habits,food diaries,precaution adoption theory},
number = {6},
pages = {692--698},
title = {{Think before you eat: photographic food diaries as intervention tools to change dietary decision making and attitudes}},
url = {http://doi.wiley.com/10.1111/j.1470-6431.2008.00725.x},
volume = {32},
year = {2008}
}
@article{Batuwita2013,
abstract = {Support Vector Machines is a very popular machine learning technique. De- spite of all its theoretical and practical advantages, SVMs could produce sub- optimal results with imbalanced datasets. That is, an SVM classifier trained on an imbalanced dataset can produce suboptimal models which are biased towards the majority class and have low performance on the minority class, like most of the other classification paradigms. There have been various data preprocessing and algorithmic techniques proposed in the literature to allevi- ate this problem for SVMs. This chapter aims to review these techniques.},
author = {Batuwita, Rukshan and Palade, Vasile},
doi = {10.1002/9781118646106},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Batuwita, Palade - Class Imbalance Learning Methods for Support Vector - Imbalanced Learning Foundations, Algorithms, Applications.pdf:pdf},
isbn = {9781118074626},
journal = {Imbalanced Learning: Foundations, Algorithms, Applications},
pages = {83--100},
title = {{Class Imbalance Learning Methods for Support Vector}},
year = {2013}
}
@inproceedings{Chen2009,
abstract = {We introduce the first visual dataset of fast foods with a total of 4,545 still images, 606 stereo pairs, 303 360° videos for structure from motion, and 27 privacy-preserving videos of eating events of volunteers. This work was motivated by research on fast food recognition for dietary assessment. The data was collected by obtaining three instances of 101 foods from 11 popular fast food chains, and capturing images and videos in both restaurant conditions and a controlled lab setting. We benchmark the dataset using two standard approaches, color histogram and bag of SIFT features in conjunction with a discriminative classifier. Our dataset and the benchmarks are designed to stimulate research in this area and will be released freely to the research community.},
author = {Chen, Mei and Dhingra, Kapil and Wu, Wen and Yang, Lei and Sukthankar, Rahul and Yang, Jie},
booktitle = {ICIP'09 Proceedings of the 16th IEEE international conference on Image processing},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Chen et al. - PFID pittsburgh fast-food image dataset - ICIP'09 Proceedings of the 16th IEEE international conference on Image processin.pdf:pdf},
isbn = {978-1-4244-5653-6},
keywords = {food image dataset,object recognition},
month = {nov},
pages = {289--292},
publisher = {IEEE Press},
title = {{PFID: pittsburgh fast-food image dataset}},
url = {http://dl.acm.org/citation.cfm?id=1818719.1818817},
year = {2009}
}
@article{Fletcher2009,
abstract = {This document has been written in an attempt to make the Support Vector Machines (SVM), initially conceived of by Cortes and Vapnik [1], as sim- ple to understand as possible for those with minimal experience of Machine Learning. It assumes basic mathematical knowledge in areas such as cal- culus, vector geometry and Lagrange multipliers. The document has been split into Theory and Application sections so that it is obvious, after the maths has been dealt with, how to actually apply the SVM for the different forms of problem that each section is centred on. The document’s first section details the problem of classification for linearly separable data and introduces the concept of margin and the essence of SVM - margin maximization. The methodology of the SVM is then extended to data which is not fully linearly separable. This soft margin SVM introduces the idea of slack variables and the trade-off between maximizing the margin and minimizing the number of misclassified variables in the second section. The third section develops the concept of SVM further so that the technique can be used for regression. The fourth section explains the other salient feature of SVM - the Kernel Trick. It explains how incorporation of this mathematical sleight of hand allows SVM to classify and regress nonlinear data.},
author = {Fletcher, Tristan},
doi = {10.1002/9780470503065.app2},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Fletcher - Support Vector Machines Explained - Online. httpsutikno. blog. undip. ac. idfiles201111SVM-Explained. pdf.Accessed 06 06 2013.pdf:pdf},
isbn = {9780470371923},
journal = {Online]. http://sutikno. blog. undip. ac. id/files/2011/11/SVM-Explained. pdf.[Accessed 06 06 2013]},
pages = {1--19},
title = {{Support Vector Machines Explained}},
url = {http://sutikno.blog.undip.ac.id/files/2011/11/SVM-Explained.pdf},
year = {2009}
}
@article{Agrawal2008,
author = {Agrawal, M and Konolige, K and Blas, M R},
doi = {10.1007/978-3-540-88693-8{\_}8},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2008/Agrawal, Konolige, Blas - CenSurE Center Surround Extremas for Realtime Feature Detection and Matching - Eccv08.pdf:pdf},
journal = {Eccv08},
pages = {IV: 102--115},
title = {{CenSurE: Center Surround Extremas for Realtime Feature Detection and Matching}},
year = {2008}
}
@book{Theodoridis2009m,
abstract = {This chapter explains clustering algorithms based on function optimization, using tools from differential calculus. Hard clustering and fuzzy and possibilistic schemes are considered, based on various types of cluster representatives, including point representatives, hyperplane representatives, and shell-shaped representatives. A distinct characteristic of most of the algorithms of this chapter is that the cluster representatives are computed using all the available vectors of X, and not only the vectors that have been assigned to the respective cluster. The chapter focuses on four major categories of algorithms that include the mixture decomposition, the fuzzy, the possibilistic and the hard clustering algorithms. In mixture decomposition algorithms, the cost function is constructed on the basis of random vectors, and assignment to clusters follows probabilistic arguments, in the spirit of the Bayesian classification. The conditional probabilities here result from the optimization process. In the fuzzy approach a proximity function between a vector and a cluster is defined. Values of the membership functions of a vector in the various clusters are interrelated. This constraint is removed in the case of the possibilistic approach. Hard clustering may be viewed as a special case of the fuzzy clustering approach, where each vector belongs exclusively to a cluster. This category includes the celebrated k-means clustering algorithm.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50016-5},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(19).pdf:pdf},
isbn = {9781597492720},
pages = {701--763},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500165},
year = {2009}
}
@misc{Boushey2010,
abstract = {The present system and method provides a more precise way to record food and beverage intake than traditional methods. The present disclosure provides custom software for use in mobile computing devices that include a digital camera. Photos captured by mobile digital devices are analyzed with image processing and comparisons to certain databases to allow a user to discretely record foods eaten. Specifically, the user captures images of the meal or snack before and after eating. The foods pictured are identified. Image processing software may identify the food or provide choices for the user. Once a food is identified and volume of the food is estimated, nutrient databases are used for calculating final portion sizes and nutrient totals.},
annote = {- Bestimmung von Kalorien durch Handy.
- Aufnahme davor und danach.
- Auswahl durch automatisch erkannte Listen von Zutaten.
- Recognition auf Server
- Gabor filter
- 50 Bilder 
- 17 f{\"{u}}r Training
- 3D Shape Reconstruction
- Volume Estimation},
author = {Boushey, Carol and Edward, Delp and Ebert, David Scott and Lutes, Kyle DelMar and Kerr, Deborah},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Boushey et al. - Dietary Assessment System and Method - Unknown.pdf:pdf},
keywords = {Color histogram,Gabor filter,SVM,Volume Estimation},
mendeley-tags = {Color histogram,Gabor filter,SVM,Volume Estimation},
month = {may},
title = {{Dietary Assessment System and Method}},
url = {http://www.google.com/patents/US20100111383},
year = {2010}
}
@article{Shroff2008,
abstract = {We propose DiaWear, a novel assistive mobile phone-based calorie monitoring system to improve the quality of life of diabetes patients and individuals with unique nutrition management needs. Our goal is to achieve improved daily semi-automatic food recognition using a mobile wearable cell phone. DiaWear currently uses a neural network classification scheme to identify food items from a captured image. It is difficult to account for the varying and implicit nature of certain foods using traditional image recognition techniques. To overcome these limitations, we introduce the role of the mobile phone as a platform to gather contextual information from the user and system in obtaining better food recognition.},
author = {Shroff, Geeta and Smailagic, Asim and Siewiorek, Daniel P.},
doi = {10.1109/ISWC.2008.4911602},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2008/Shroff, Smailagic, Siewiorek - Wearable context-aware food recognition for calorie monitoring - Proceedings - International Symposium on.pdf:pdf},
isbn = {9781424426379},
issn = {15504816},
journal = {Proceedings - International Symposium on Wearable Computers, ISWC},
pages = {119--120},
title = {{Wearable context-aware food recognition for calorie monitoring}},
year = {2008}
}
@article{Svetkey2008,
abstract = {CONTEXT: Behavioral weight loss interventions achieve short-term success, but re-gain is common.

OBJECTIVE: To compare 2 weight loss maintenance interventions with a self-directed control group.

DESIGN, SETTING, AND PARTICIPANTS: Two-phase trial in which 1032 overweight or obese adults (38{\%} African American, 63{\%} women) with hypertension, dyslipidemia, or both who had lost at least 4 kg during a 6-month weight loss program (phase 1) were randomized to a weight-loss maintenance intervention (phase 2). Enrollment at 4 academic centers occurred August 2003-July 2004 and randomization, February-December 2004. Data collection was completed in June 2007.

INTERVENTIONS: After the phase 1 weight-loss program, participants were randomized to one of the following groups for 30 months: monthly personal contact, unlimited access to an interactive technology-based intervention, or self-directed control. Main Outcome Changes in weight from randomization.

RESULTS: Mean entry weight was 96.7 kg. During the initial 6-month program, mean weight loss was 8.5 kg. After randomization, weight regain occurred. Participants in the personal-contact group regained less weight (4.0 kg) than those in the self-directed group (5.5 kg; mean difference at 30 months, -1.5 kg; 95{\%} confidence interval [CI], -2.4 to -0.6 kg; P = .001). At 30 months, weight regain did not differ between the interactive technology-based (5.2 kg) and self-directed groups (5.5 kg; mean difference -0.3 kg; 95{\%} CI, -1.2 to 0.6 kg; P = .51); however, weight regain was lower in the interactive technology-based than in the self-directed group at 18 months (mean difference, -1.1 kg; 95{\%} CI, -1.9 to -0.4 kg; P = .003) and at 24 months (mean difference, -0.9 kg; 95{\%} CI, -1.7 to -0.02 kg; P = .04). At 30 months, the difference between the personal-contact and interactive technology-based group was -1.2 kg (95{\%} CI -2.1 to -0.3; P = .008). Effects did not differ significantly by sex, race, age, and body mass index subgroups. Overall, 71{\%} of study participants remained below entry weight.

CONCLUSIONS: The majority of individuals who successfully completed an initial behavioral weight loss program maintained a weight below their initial level. Monthly brief personal contact provided modest benefit in sustaining weight loss, whereas an interactive technology-based intervention provided early but transient benefit.

TRIAL REGISTRATION: clinicaltrials.gov Identifier: NCT00054925.},
author = {Svetkey, Laura P and Stevens, Victor J and Brantley, Phillip J and Appel, Lawrence J and Hollis, Jack F and Loria, Catherine M and Vollmer, William M and Gullion, Christina M and Funk, Kristine and Smith, Patti and Samuel-Hodge, Carmen and Myers, Valerie and Lien, Lillian F and Laferriere, Daniel and Kennedy, Betty and Jerome, Gerald J and Heinith, Fran and Harsha, David W and Evans, Pamela and Erlinger, Thomas P and Dalcin, Arline T and Coughlin, Janelle and Charleston, Jeanne and Champagne, Catherine M and Bauck, Alan and Ard, Jamy D and Aicher, Kathleen},
doi = {10.1001/jama.299.10.1139},
issn = {1538-3598},
journal = {JAMA},
keywords = {Adult,Aged,Aged, 80 and over,Communication,Continuity of Patient Care,Energy Intake,Energy Metabolism,Female,Humans,Internet,Male,Middle Aged,Obesity,Obesity: prevention {\&} control,Risk Reduction Behavior,Weight Loss},
month = {mar},
number = {10},
pages = {1139--48},
pmid = {18334689},
title = {{Comparison of strategies for sustaining weight loss: the weight loss maintenance randomized controlled trial.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18334689},
volume = {299},
year = {2008}
}
@book{Theodoridis2009g,
abstract = {This chapter examines feature generation with a focus on image and audio classification. Feature generation is a procedure that computes new variables that in one way or another originate from the stored values of the image array I(m, n). Some of the feature generation techniques can be considered common and can be applicable in both visual and audio modalities. A large number of features are the result of different approaches to exploit the specific nature of the signals and encode the required classification information in a more efficient way. This chapter also focuses on first- and second-order statistics features as well as the run-length method. The chapter discusses typical features used to characterize and classify audio information. The chapter presents a description of statistical properties of signals and images and the ways these can be exploited to extract information-rich features for classification. The chapter examines whether the notion of self-similarity is extendable to stochastic processes and, if it is, how useful it can be. The chain code for shape description is discussed in this chapter. Computer exercises are then offered to generate these features and use them for classification for some case studies.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50009-8},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(18).pdf:pdf},
isbn = {9781597492720},
pages = {411--479},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500098},
year = {2009}
}
@article{Matsuda2012,
abstract = {In this paper, we propose a two-step method to recognize multiple-food images by detecting candidate regions with several methods and classifying them with various kinds of features. In the first step, we detect several candidate re- gions by fusing outputs of several region detectors including Felzenszwalb’s deformable part model (DPM) [1], a circle de- tector and the JSEG region segmentation. In the second step, we apply a feature-fusion-based food recognition method for bounding boxes of the candidate regions with various kinds of visual features including bag-of-features of SIFT and CSIFT with spatial pyramid (SP-BoF), histogram of oriented gradi- ent (HoG), and Gabor texture features. In the experiments, we estimated ten food candidates for multiple-food images in the descending order of the confi- dence scores. As results, we have achieved the 55.8{\%} classi- fication rate, which improved the baseline result in case of us- ing only DPM by 14.3 points, for a multiple-food image data set. This demonstrates that the proposed two-step method is effective for recognition of multiple-food images.},
annote = {UEC FOOD 100},
author = {Matsuda, Yuji and Hoashi, Hajime and Yanai, Keiji},
doi = {10.1109/ICME.2012.157},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Matsuda, Hoashi, Yanai - Recognition of multiple-food images by detecting candidate regions - Proceedings - IEEE International Conferenc.pdf:pdf},
isbn = {978-1-4673-1659-0},
issn = {19457871},
journal = {Proceedings - IEEE International Conference on Multimedia and Expo},
keywords = {multiple kernel learning,multiple-food image,region detection,window search},
pages = {25--30},
title = {{Recognition of multiple-food images by detecting candidate regions}},
year = {2012}
}
@misc{Cox2003,
abstract = {Two separate white light illuminated images are acquired of a plate of food. The image data is processed, and the two images are compared to determine volume of particular food zones. In parallel to that, the food type in each zone is identified by a food recognition processor nd reference to a stored nutritional data bank. These two values are combined with the foods' nutritional value in the data bank to provide zone-by-zone nutrient content information. These can be individually displayed, and/or the total displayed so that the user knows the nutritional value of the food on his plate in terms of total calories, percent fat, percent protein, and percent carbohydrate. In addition, the approximate milligrams each of principal vitamin, mineral, fiber, enzyme and phytonutrient on the plate can be displayed sequentially. Provision is made to download data into a PDA or PC.},
annote = {- Kamera mit zwei Lampen nimmt zwei Bilder auf.
- Schatten werden vermessen -{\&}gt; Volumen
- Bild wird anhand von Farbe und Shape klassifiziert

Wahrscheinlich nicht sehr robust.},
author = {Cox, Dale},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2003/Cox - Personal food analyzer - Unknown.pdf:pdf},
keywords = {Descission Tree},
mendeley-tags = {Descission Tree},
month = {apr},
title = {{Personal food analyzer}},
url = {https://www.google.com.ar/patents/US20030076983},
year = {2003}
}
@article{Chapelle1999,
author = {Chapelle, O. and Haffner, P. and Vapnik, V.N.},
doi = {10.1109/72.788646},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1999/Chapelle, Haffner, Vapnik - Support vector machines for histogram-based image classification - IEEE Transactions on Neural Networks.pdf:pdf},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Classification tree analysis,Corel stock photo collection,Histograms,Image classification,Image databases,Image recognition,Kernel,Polynomials,Support vector machine classification,Support vector machines,Web pages,feature space dimensionality,heavy-tailed RBF kernels,high-dimensional histograms,histogram-based image classification,image classification,learning (artificial intelligence),linear SVM,radial basis function networks,remapping,support vector machines},
language = {English},
number = {5},
pages = {1055--1064},
publisher = {IEEE},
title = {{Support vector machines for histogram-based image classification}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=788646},
volume = {10},
year = {1999}
}
@article{Kumar2015,
abstract = {This paper deals with automatic systems for image recipe recognition. For this purpose, we compare and evaluate leading vision-based and text-based technologies on a new very large multimodal dataset (UPMC Food-101) containing about 100,000 recipes for a total of 101 food categories. Each item in this dataset is represented by one image plus textual information. We present deep experiments of recipe recognition on our dataset using visual, textual information and fusion. Additionally, we present experiments with text-based embedding technology to represent any food word in a semantical continuous space. We also compare our dataset features with a twin dataset provided by ETHZ university: we revisit their data collection protocols and carry out transfer learning schemes to highlight similarities and differences between both datasets. Finally, we propose a real application for daily users to identify recipes. This application is a web search engine that allows any mobile device to send a query image and retrieve the most relevant recipes in our dataset.},
annote = {UPMC Food 101},
author = {Kumar, Devinder and Thome, Nicolas and Cord, Matthieu and Precioso, Frederic},
doi = {10.1109/ICMEW.2015.7169757},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Kumar et al. - Recipe recognition with large multimodal food dataset - 2015 IEEE International Conference on Multimedia {\&} Expo Workshops.pdf:pdf},
isbn = {978-1-4799-7079-7},
journal = {2015 IEEE International Conference on Multimedia {\&} Expo Workshops (ICMEW)},
keywords = {Accuracy,Feature extraction,Google,HTML,Internet,Protocols,Training,UPMC Food-101,Visualization,Web search engine,computer vision,data collection protocols,food categories,food technology,image fusion,image recipe recognition,image recognition,image retrieval,mobile device,multimodal dataset,multimodal food dataset,query image,relevant recipe retrieval,search engines,semantical continuous space,text analysis,text-based embedding technology,text-based technology,transfer learning schemes,vision-based technology},
number = {1},
pages = {1--6},
title = {{Recipe recognition with large multimodal food dataset}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=7169757},
year = {2015}
}
@article{Kim2010,
abstract = {There is a growing concern about chronic diseases and other health problems related to diet including obesity and cancer. The need to accurately measure diet (what foods a person consumes) becomes imperative. Dietary intake provides valuable insights for mounting intervention programs for prevention of chronic diseases. Measuring accurate dietary intake is considered to be an open research problem in the nutrition and health fields. In this paper, we describe a novel mobile telephone food record that will provide an accurate account of daily food and nutrient intake. Our approach includes the use of image analysis tools for identification and quantification of food that is consumed at a meal. Images obtained before and after foods are eaten are used to estimate the amount and type of food consumed. The mobile device provides a unique vehicle for collecting dietary information that reduces the burden on respondents that are obtained using more classical approaches for dietary assessment. We describe our approach to image analysis that includes the segmentation of food items, features used to identify foods, a method for automatic portion estimation, and our overall system architecture for collecting the food intake information. Color},
author = {Kim, Sungye},
doi = {10.1109/JSTSP.2010.2051471.The},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Kim - The Use of Mobile Devices in Aiding Dietary Assessment and Evaluation - IEEE Journal of Selected Topics in Signal Processing.pdf:pdf},
journal = {IEEE Journal of Selected Topics in Signal Processing},
keywords = {Volume Estimation},
mendeley-tags = {Volume Estimation},
number = {4},
pages = {756--766},
title = {{The Use of Mobile Devices in Aiding Dietary Assessment and Evaluation}},
volume = {4},
year = {2010}
}
@article{Shotton2008,
author = {Shotton, J and Johnson, M and Cipolla, R},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2008/Shotton, Johnson, Cipolla - Semantic Texton Forest for Image Categorization and Segmentation - Proceedings of the conference on Computer.pdf:pdf},
journal = {Proceedings of the conference on Computer Vision and Pattern Recognition},
keywords = {Semantic Segmentation; Image Parsing; Random Fores},
pages = {1--8},
title = {{Semantic Texton Forest for Image Categorization and Segmentation}},
year = {2008}
}
@article{Hollis2008,
abstract = {BACKGROUND: To improve methods for long-term weight management, the Weight Loss Maintenance (WLM) trial, a four-center randomized trial, was conducted to compare alternative strategies for maintaining weight loss over a 30-month period. This paper describes methods and results for the initial 6-month weight-loss program (Phase I).

METHODS: Eligible adults were aged > or =25, overweight or obese (BMI=25-45 kg/m2), and on medications for hypertension and/or dyslipidemia. Anthropomorphic, demographic, and psychosocial measures were collected at baseline and 6 months. Participants (n=1685) attended 20 weekly group sessions to encourage calorie restriction, moderate-intensity physical activity, and the DASH (dietary approaches to stop hypertension) dietary pattern. Weight-loss predictors with missing data were replaced by multiple imputation.

RESULTS: Participants were 44{\%} African American and 67{\%} women; 79{\%} were obese (BMI> or =30), 87{\%} were taking anti-hypertensive medications, and 38{\%} were taking antidyslipidemia medications. Participants attended an average of 72{\%} of 20 group sessions. They self-reported 117 minutes of moderate-intensity physical activity per week, kept 3.7 daily food records per week, and consumed 2.9 servings of fruits and vegetables per day. The Phase-I follow-up rate was 92{\%}. Mean (SD) weight change was -5.8 kg (4.4), and 69{\%} lost at least 4 kg. All race-gender subgroups lost substantial weight: African-American men (-5.4 kg +/- 7.7); African-American women (-4.1 kg +/- 2.9); non-African-American men (-8.5 kg +/- 12.9); and non-African-American women (-5.8 kg +/- 6.1). Behavioral measures (e.g., diet records and physical activity) accounted for most of the weight-loss variation, although the association between behavioral measures and weight loss differed by race and gender groups.

CONCLUSIONS: The WLM behavioral intervention successfully achieved clinically significant short-term weight loss in a diverse population of high-risk patients.},
author = {Hollis, Jack F and Gullion, Christina M and Stevens, Victor J and Brantley, Phillip J and Appel, Lawrence J and Ard, Jamy D and Champagne, Catherine M and Dalcin, Arlene and Erlinger, Thomas P and Funk, Kristine and Laferriere, Daniel and Lin, Pao-Hwa and Loria, Catherine M and Samuel-Hodge, Carmen and Vollmer, William M and Svetkey, Laura P},
doi = {10.1016/j.amepre.2008.04.013},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2008/Hollis et al. - Weight loss during the intensive intervention phase of the weight-loss maintenance trial. - American journal of preventi.pdf:pdf},
issn = {0749-3797},
journal = {American journal of preventive medicine},
keywords = {Adult,Combined Modality Therapy,Diet,Diet Records,Exercise,Female,Humans,Male,Middle Aged,Obesity,Obesity: diet therapy,Obesity: therapy,Overweight,Overweight: diet therapy,Overweight: therapy,Patient Compliance,Patient Compliance: statistics {\&} numerical data,Weight Loss},
month = {aug},
number = {2},
pages = {118--26},
pmid = {18617080},
title = {{Weight loss during the intensive intervention phase of the weight-loss maintenance trial.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2515566{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {35},
year = {2008}
}
@book{Theodoridis2009n,
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50001-3},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(3).pdf:pdf},
isbn = {9781597492720},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500013},
year = {2009}
}
@book{Theodoridis2009e,
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50021-9},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(2).pdf:pdf},
isbn = {9781597492720},
keywords = {appendix},
mendeley-tags = {appendix},
pages = {930--945},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500219},
year = {2009}
}
@article{Srivastava2014,
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Srivastava et al. - Dropout A Simple Way to Prevent Neural Networks from Overfitting - Journal of Machine Learning Research.pdf:pdf},
journal = {Journal of Machine Learning Research},
pages = {1929--1958},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
url = {http://jmlr.org/papers/v15/srivastava14a.html},
volume = {15},
year = {2014}
}
@inproceedings{Kagaya2015,
author = {Kagaya, Hokuto and Aizawa, Kiyoharu and Ogawa, Makoto},
booktitle = {ACM Multimedia},
doi = {10.13140/2.1.3082.1120},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Kagaya, Aizawa, Ogawa - Food Detection and Recognition Using Convolutional Neural Network Food Detection and Recognition Using Convoluti.pdf:pdf},
isbn = {9781450330633},
keywords = {convolu-,deep learning,food detection,food recognition,tional neural network},
number = {August},
title = {{Food Detection and Recognition Using Convolutional Neural Network Food Detection and Recognition Using Convolutional Neural Network}},
year = {2015}
}
@book{Theodoridis2009r,
abstract = {This chapter presents clustering algorithms based on different ideas, which cannot be grouped under a single philosophy. The chapter discuses clustering algorithms based on graph theory concepts, such as the minimum spanning tree, the directed tree, and spectral clustering. The second category of competitive learning algorithms is also explained. The third category includes branch and bound algorithms, and guarantees to provide globally optimal clustering, in terms of a prespecified optimality criterion, at the cost of increased computational requirements. The fourth category discussed in the chapter contains algorithms that are based on morphological transformations. The fifth category contains algorithms that are not based on cluster representatives but, instead, seek to place boundaries between clusters. Algorithms of the sixth category treat clusters as dense in data regions of the feature space separated by regions sparse in data. The seventh category includes additional algorithms that are based on function optimization, such as simulated annealing and deterministic annealing. This category also includes genetic algorithms modified suitably for clustering tasks. The final eighth category of algorithms discussed in this chapter includes algorithms that combine clustering in order to produce a final one.},
author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
booktitle = {Pattern Recognition},
doi = {10.1016/B978-1-59749-272-0.50017-7},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Theodoridis, Koutroumbas - Pattern Recognition - Pattern Recognition(14).pdf:pdf},
isbn = {9781597492720},
pages = {765--862},
publisher = {Elsevier},
title = {{Pattern Recognition}},
url = {http://www.sciencedirect.com/science/article/pii/B9781597492720500177},
year = {2009}
}
@article{Yang2009,
archivePrefix = {arXiv},
arxivId = {1504.06897},
author = {Yang, J and Yu, K and Gong, Y and Huang, T},
doi = {10.1109/CVPR.2009.5206757},
eprint = {1504.06897},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2009/Yang et al. - Linear spatial pyramid matching using sparse coding for image classification - Computer Vision and Pattern {\ldots}.pdf:pdf},
isbn = {1063-6919 VO -},
issn = {1063-6919},
journal = {Computer Vision and Pattern  {\ldots}},
title = {{Linear spatial pyramid matching using sparse coding for image classification}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5206757},
year = {2009}
}
@article{Canny1986,
abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
author = {Canny, John},
doi = {10.1109/TPAMI.1986.4767851},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1986/Canny - A Computational Approach to Edge Detection - IEEE Transactions on Pattern Analysis and Machine Intelligence.pdf:pdf},
isbn = {0162-8828},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Edge detection,feature extraction,image processing,machine vision,multiscale image analysis},
number = {6},
pages = {679--698},
pmid = {21869365},
title = {{A Computational Approach to Edge Detection}},
volume = {PAMI-8},
year = {1986}
}
@phdthesis{Mezgec2015,
abstract = {As people become more and more aware of the importance of a healthy diet, a need for automatic food and drink recognition systems has arisen. Such a system can not only provide recognition of the food or drink item, but can also estimate its nutritional value, making it useful for diet planning. In this paper, we describe the problems of food and drink recognition and take a look at the research that has been published so far in this research field. We focus on popular and influential solutions and in particular, we give an overview of three interesting papers: two for food recognition and one for drink recognition, each with its own approach to the problem. Finally, we give our critical review of the research in the field and suggest what the future research work should focus on.},
author = {Mezgec, Simon},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2015/Mezgec - Modern Methods and Algorithms for Food and Drink Recognition Using Average Quality Photograph - Unknown.pdf:pdf},
keywords = {Computer Vision,drink recognition,electronic nose,electronic tongue.,food recognition,image dataset},
school = {Ljubjana},
title = {{Modern Methods and Algorithms for Food and Drink Recognition Using Average Quality Photograph}},
year = {2015}
}
@phdthesis{Pouladzadeh2013,
abstract = {As people across the globe are becoming more interested in watching their weight, eating more healthily, and avoiding obesity, a system that can measure calories and nutrition in everyday meals can be very useful. Recently, there has been an increase in the usage of personal mobile technology such as smartphones or tablets, which users carry with them practically all the time. In this paper, we proposed a food calorie and nutrition measurement system that can help patients and dieticians to measure and manage daily food intake. Our system is built on food image processing and uses nutritional fact tables. Via a special calibration technique, our system uses the built-in camera of such mobile devices and records a photo of the food before and after eating it in order to measure the consumption of calorie and nutrient components. The proposed algorithm used color, texture and contour segmentation and extracted important features such as shape, color, size and texture. Using various combinations of these features and applying a support vector machine as a classifier, a good classification was achieved and simulation results show that the algorithm recognizes food categories with an accuracy rate of 92.2{\%}, on average.},
author = {Pouladzadeh, Parisa},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2013/Pouladzadeh - An Image Processing and Pattern Analysis Approach for Food Recognition - Unknown.pdf:pdf},
isbn = {http://hdl.handle.net/10393/23677},
keywords = {Classification,Food recognition,Segmantation},
language = {en},
school = {University of Ottawa},
title = {{An Image Processing and Pattern Analysis Approach for Food Recognition}},
url = {http://www.ruor.uottawa.ca/handle/10393/23677},
year = {2013}
}
@article{Boser1992,
abstract = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of classifiaction functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms. 1 INTRODUCTION Good generalization performance of pattern classifiers is achieved when the capacity of the classification function is matched to the size of the training set. Classifiers with a large numb...},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
doi = {10.1.1.21.3818},
eprint = {arXiv:1011.1669v3},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/1992/Boser, Guyon, Vapnik - A Training Algorithm for Optimal Margin Classifiers - Proceedings of the Fifth Annual ACM Workshop on Computation.pdf:pdf},
isbn = {089791497X},
issn = {0-89791-497-X},
journal = {Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory},
pages = {144--152},
pmid = {25246403},
title = {{A Training Algorithm for Optimal Margin Classifiers}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.3818},
year = {1992}
}
@misc{ReboucasdeOliveira2012,
abstract = {The present invention relates to a method for automatic food recognition by means of portable devices equipped with digital cameras. With this system, it is possible to identify a previously established food menu. To this purpose, a semi-automated method of segmentation is applied to delineate the regions in which each type of food in an image of a plate of food, captured by a user. Pattern recognition techniques are used in images, integrated into a system whose goal is to label each type of food contained in the photo of a plate of food. No type of preprocessing is performed to correct deficiencies in capturing the image, just using the auto-focus component present in the portable device to capture a clear image.},
annote = {- Erkennung mit Color und Texture.

- Segmentierung mit Color

- Klassifizierung mit SVMs (radial based kernel-type function)
- Multithreading auf Handy.
- {\&}quot;To prevent the image from the plate of being captured in a distorted or unfocused, auto-focus of the device is triggered, preventing this problem.{\&}quot; {\&}lt;- Wahnsinn. Was f{\"{u}}r eine gute Idee},
author = {{Reboucas de Oliveira}, Luciano and {Manuel de Freitas Jorge}, Eduardo and {Almeida de Azevedo Filho}, Alberto and {Franco Costa}, Victor},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2012/Reboucas de Oliveira et al. - System for Food Recognition Method Using Portable Devices Having Digital Cameras - Unknown.pdf:pdf},
keywords = {Gaussian difference,coefficient of spatial variation},
mendeley-tags = {Gaussian difference,coefficient of spatial variation},
month = {jul},
title = {{System for Food Recognition Method Using Portable Devices Having Digital Cameras}},
url = {http://www.google.com/patents/US20120170801},
year = {2012}
}
@phdthesis{Xia,
author = {Xia, Yinghui},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2016/Xia - Cuisine and Flavor Classification Using Recipes and Food Images - Unknown.pdf:pdf},
title = {{Cuisine and Flavor Classification Using Recipes and Food Images}},
url = {http://web.stanford.edu/{~}yinghui/files/cuisine-flavor-classification.pdf},
year = {2016}
}
@article{Khanna2010,
abstract = {In this paper, we describe the Technology Assisted Dietary Assessment (TADA) project at Purdue University. Dietary intake, what someone eats during the course of a day, provides valuable insights for mounting intervention programs for prevention of many chronic diseases such as obesity and cancer. Accurate methods and tools to assess food and nutrient intake are essential for research on the association between diet and health. An overview of our methods used in the TADA project is presented. Our approach includes the use of image analysis tools for identification and quantification of food that is consumed at a meal. Images obtained before and after foods are eaten are used to estimate the amount and type of food consumed.},
author = {Khanna, Nitin and Boushey, Carol J. and Kerr, Deborah and Okos, Martin and Ebert, David S. and Delp, Edward J.},
doi = {10.1109/ISM.2010.50},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Khanna et al. - An overview of the Technology Assisted Dietary Assessment project at Purdue University - Proceedings - 2010 IEEE Interna.pdf:pdf},
isbn = {9780769542171},
journal = {Proceedings - 2010 IEEE International Symposium on Multimedia, ISM 2010},
keywords = {Classification,Diet record method,Dietary assessment,Feature extraction,Image texture,Mobile device,Mobile telephone,Pattern recognition,Volume estimation},
pages = {290--295},
pmid = {22020443},
title = {{An overview of the Technology Assisted Dietary Assessment project at Purdue University}},
year = {2010}
}
@article{Tola2010,
abstract = {In this paper, we introduce a local image descriptor, DAISY, which is very efficient to compute densely. We also present an EM-based algorithm to compute dense depth and occlusion maps from wide-baseline image pairs using this descriptor. This yields much better results in wide-baseline situations than the pixel and correlation-based algorithms that are commonly used in narrow-baseline stereo. Also, using a descriptor makes our algorithm robust against many photometric and geometric transformations. Our descriptor is inspired from earlier ones such as SIFT and GLOH but can be computed much faster for our purposes. Unlike SURF, which can also be computed efficiently at every pixel, it does not introduce artifacts that degrade the matching performance when used densely. It is important to note that our approach is the first algorithm that attempts to estimate dense depth maps from wide-baseline image pairs, and we show that it is a good one at that with many experiments for depth estimation accuracy, occlusion detection, and comparing it against other descriptors on laser-scanned ground truth scenes. We also tested our approach on a variety of indoor and outdoor scenes with different photometric and geometric transformations and our experiments support our claim to being robust against these.},
author = {Tola, Engin and Lepetit, Vincent and Fua, Pascal},
doi = {10.1109/TPAMI.2009.77},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2010/Tola, Lepetit, Fua - DAISY an efficient dense descriptor applied to wide-baseline stereo. - IEEE transactions on pattern analysis and ma.pdf:pdf},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
keywords = {Algorithms,Artificial Intelligence,Image Interpretation, Computer-Assisted,Image Interpretation, Computer-Assisted: methods,Imaging, Three-Dimensional,Imaging, Three-Dimensional: methods,Pattern Recognition, Automated,Pattern Recognition, Automated: methods,Photogrammetry,Photogrammetry: methods,Subtraction Technique},
language = {English},
month = {may},
number = {5},
pages = {815--30},
pmid = {20299707},
publisher = {IEEE},
title = {{DAISY: an efficient dense descriptor applied to wide-baseline stereo.}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=4815264},
volume = {32},
year = {2010}
}
@article{Lowe2004,
abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
author = {Lowe, David G.},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2004/Lowe - Distinctive image features from scale-invariant keypoints - International Journal of Computer Vision.pdf:pdf},
journal = {International Journal of Computer Vision},
keywords = {Image matching,Invariant features,Object recognition,Scale invariance},
number = {2},
pages = {91--110},
title = {{Distinctive image features from scale-invariant keypoints}},
volume = {60},
year = {2004}
}
@article{Bossard2014,
abstract = {In this paper we address the problem of automatically recognizing pictured dishes. To this end, we introduce a novel method to mine discriminative parts using Random Forests (rf), which allows us to mine for parts simultaneously for all classes and to share knowledge among them. To improve eﬃciency of mining and classiﬁcation, we only consider patches that are aligned with image superpixels, which we call components. To measure the performance of our rf component mining for food recognition, we introduce a novel and challenging dataset of 101 food categories, with 101’000 images. With an average accuracy of 50.76{\%}, our model outperforms alternative classiﬁcation methods except for cnn, including svm classiﬁcation on Improved Fisher Vectors and existing discriminative part-mining algorithms by 11.88{\%} and 8.13{\%}, respectively. On the challenging mit-Indoor dataset, our method compares nicely to other s-o-a component-based classiﬁcation methods.},
annote = {ETHZ Food 101},
archivePrefix = {arXiv},
arxivId = {10.1007/978-3-319-10599-4{\_}29},
author = {Bossard, Lukas and Guillaumin, Matthieu and {Van Gool}, Luc},
doi = {10.1007/978-3-319-10599-4{\_}29},
eprint = {978-3-319-10599-4{\_}29},
file = {:D$\backslash$:/OneDrive/Studium/Studium/7. Semester/BA/Papers/2014/Bossard, Guillaumin, Van Gool - Food-101 -- Mining Discriminative Components with Random Forests - Computer Vision - ECCV 2014.pdf:pdf},
isbn = {978-3-319-10598-7},
issn = {978-3-319-10598-7},
journal = {Computer Vision - ECCV 2014},
keywords = {Discriminative part mining,Food recognition,Image classiﬁcation,Random Forest,discriminative part mining,food recognition,forest,image classification,random},
pages = {446--461},
primaryClass = {10.1007},
publisher = {Springer International Publishing},
title = {{Food-101 -- Mining Discriminative Components with Random Forests}},
url = {https://www.vision.ee.ethz.ch/datasets{\_}extra/food-101/},
year = {2014}
}
